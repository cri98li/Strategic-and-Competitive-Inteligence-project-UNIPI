{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "22129e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "9bc7d3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../data/fix_ipc_class_dict.json\") as json_file:\n",
    "    ipc_class_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "46c8eafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"../data/subest1_filtrato.csv\")\n",
    "df = pd.read_csv(\"../data/data_subset1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "df2405e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.title = df.title.str.lower()\n",
    "df.abstract = df.abstract.str.lower()\n",
    "df.claims = df.claims.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ba1ca4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>priority_date</th>\n",
       "      <th>ipc_classes</th>\n",
       "      <th>assignee</th>\n",
       "      <th>inventors</th>\n",
       "      <th>docdb_family_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>claims</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US2009216698_A1.txt</td>\n",
       "      <td>2008-02-22</td>\n",
       "      <td>2009-08-27</td>\n",
       "      <td>2008-02-22</td>\n",
       "      <td>G06F15/18,G06N5/02</td>\n",
       "      <td>XEROX CORPORATIONANDREOLI, JEAN-MARCBOUCHARD, GUILLAUME</td>\n",
       "      <td>ANDREOLI, JEAN-MARCBOUCHARD, GUILLAUME</td>\n",
       "      <td>40999265</td>\n",
       "      <td>temporal events analysis employing tree induction</td>\n",
       "      <td>an events analysis method comprises: optimizing respective to a set of training data a set of branching transition likelihood parameters associating parent events of type k with child events of type k' in branching processes; inferring a most probable branching process for a set of input data comprising events based on the optimized set of branching transition likelihood parameters; and identifying rare or unusual events of the set of input data based on the inferred most probable branching process. an events analysis apparatus includes a probabilistic branching process learning engine configured to optimize the set of branching transition likelihood parameters, and a probabilistic branching process inference engine configured to infer the most probable branching process.</td>\n",
       "      <td>1. an events analyzer comprising: a probabilistic branching process learning engine configured to optimize respective to a set of training data a set of branching transition likelihood parameters associating parent events of type k with child events of type k′ in branching processes; and a probabilistic branching process inference engine configured to infer a most probable branching process for a set of input data comprising events based on the optimized set of branching transition likelihood parameters.2. the events analyzer as set forth in claim 1, wherein the set of branching transition likelihood parameters include: (i) type transition likelihood parameters indicative of likelihood that one or more events of type k′ follow an event of type k, and (ii) one or more lifetime parameters for each event type k indicative of a statistical lifetime of events of type k.3. the events analyzer as set forth in claim 2, wherein the probabilistic branching process learning engine models branching as a geometrical process.4. the events analyzer as set forth in claim 3, wherein the probabilistic branching process learning engine applies a maximum likelihood algorithm to optimize respective to the set of training data at least one of (i) the type transition likelihood parameters and (ii) the lifetime parameters.5. the events analyzer as set forth in claim 1, wherein the probabilistic branching process learning engine applies a maximum likelihood algorithm to optimize the branching transition likelihood parameters respective to the set of training data.6. the events analyzer as set forth in claim 1, wherein the set of branching transition likelihood parameters include type transition likelihood parameters indicative of likelihood that one or more events of type k′ follow an event of type k, the type transition likelihood parameters being geometric distribution parameters.7. the events analyzer as set forth in claim 1, further comprising: a rare or unusual events identifier configured to identify rare or unusual events based on transition likelihoods of the most probable branching process.8. the events analyzer as set forth in claim 7, further comprising: a user interface including a display device configured to display a plot of the set of input data with rare or unusual events emphasized in the displayed plot.9. the events analyzer as set forth in claim 7, further comprising: an events logger configured to receive and log events associated with a monitored device, the set of input data comprising events comprising at least a portion of the events logged by the events logger.10. the events analyzer as set forth in claim 9, wherein the events logger is configured to receive and log events associated with one or more printing devices.11. a computer readable medium or media encoded with instructions executable on a computer or other digital processing device to perform an events analysis method including (i) inferring a most probable branching process for a set of input data comprising events based on an optimized set of branching transition likelihood parameters and (ii) identifying rare or unusual events based on the inferred most probable branching process.12. the computer readable medium or media as set forth in claim 11, wherein the set of optimized branching transition likelihood parameters include: (i) type transition likelihood parameters indicative of likelihood that one or more events of type k′ follow an event of type k, and (ii) one or more lifetime parameters for each event type k indicative of a statistical lifetime of events of type k.13. the computer readable medium or media as set forth in claim 11, wherein the identifying includes identifying rare or unusual events based on transition likelihoods of the most probable branching process.14. the computer readable medium or media as set forth in claim 11, wherein the encoded events analysis method further includes displaying a plot of the set of input data with rare or unusual events emphasized in the displayed plot.15. the computer readable medium or media as set forth in claim 11, wherein the encoded events analysis method further includes receiving and logging events, the set of input data comprising at least a portion of the logged events.16. the computer readable medium or media as set forth in claim 11, wherein the encoded events analysis method further includes receiving and logging events from one or more printing devices, the set of input data comprising at least a portion of the logged printing device events.17. an events analysis method comprising: optimizing respective to a set of training data a set of branching transition likelihood parameters associating parent events of type k with child events of type k′ in branching processes; inferring a most probable branching process for a set of input data comprising events based on the optimized set of branching transition likelihood parameters; and identifying rare or unusual events of the set of input data based on the inferred most probable branching process.18. the events analysis method as set forth in claim 17, wherein set of the input data is different from the set of training data.19. the events analysis method as set forth in claim 17, wherein the set of branching transition likelihood parameters include: (i) type transition likelihood parameters indicative of likelihood that one or more events of type k follow an event of type k, and (ii) one or more lifetime parameters for each event type k indicative of a statistical lifetime of events of type k.20. the events analysis method as set forth in claim 19, wherein the optimizing comprises: applying a maximum likelihood algorithm to optimize respective to the set of training data at least one of (i) the type transition likelihood parameters and (ii) the lifetime parameters.21. the events analysis method as set forth in claim 19, wherein the optimizing comprises: applying a maximum likelihood algorithm to optimize the branching transition likelihood parameters respective to the set of training data.22. the events analysis method as set forth in claim 17, wherein the identifying comprises: identifying rare or unusual events based on transition likelihoods of the most probable branching process.23. the events analysis method as set forth in claim 17, further comprising: displaying a plot of the set of input data with rare or unusual events emphasized in the displayed plot.24. the events analyzer as set forth in claim 17, further comprising: receiving the set of input data comprising events from one or more printing devices.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US2020018760_A1.txt</td>\n",
       "      <td>2019-09-23</td>\n",
       "      <td>2020-01-16</td>\n",
       "      <td>2007-03-27</td>\n",
       "      <td>G01N33/574</td>\n",
       "      <td>IMMUNOVIA</td>\n",
       "      <td>BORREBAECK, CARL, ARNE, KRISTERWINGREN, LARS, BERTIL, CHRISTER</td>\n",
       "      <td>39493874</td>\n",
       "      <td>protein signature/markers for the detection of adenocarcinoma</td>\n",
       "      <td>the present invention provides a method for determining the presence of pancreatic adenocarcinoma in an individual and/or for determining the survival time of an individual afflicted with pancreatic adenocarcinoma comprising the steps of: (a) providing a serum or plasma sample to be tested; and (b) determining a protein signature of the test sample by measuring the presence and/or amount in the test sample of one or more selected proteins; wherein the presence and/or amount in the test sample of one or more proteins selected from the group defined in table 1 is indicative of the presence of pancreatic adenocarcinoma. the invention also provides an array and a kit suitable for use in the methods of the invention.</td>\n",
       "      <td>1. a method for determining the presence of pancreatic adenocarcinoma in an individual comprising the steps of: a) providing a serum or plasma sample to be tested; b) determining a protein signature of the test sample by measuring the presence and/or amount in the test sample of one or more proteins selected from the group defined in table 1; wherein the presence and/or amount in the test sample of one or more proteins selected from the group defined in table 1 is indicative of the presence of pancreatic adenocarcinoma.2. the method according to claim 1 wherein the one or more proteins selected from the group defined in table 1 includes il-5 and c5.3. the method according to claim 1 further comprising the steps of: c) providing a control serum or plasma sample from an individual not afflicted with pancreatic adenocarcinoma; d) determining a protein signature of the control sample by measuring the presence and/or amount in the control sample of the one or more proteins measured in step (b); wherein the presence of pancreatic adenocarcinoma is identified in the event that the presence and/or amount in the test sample of the one or more proteins measured in step (b) is different from the presence and/or amount in the control sample of the one or more proteins measured in step (b).4. the method according to claim 1, wherein step (b) comprises measuring the presence and/or amount in the test sample of all of the proteins defined in table 1.5. a method for determining the survival time of an individual afflicted with pancreatic adenocarcinoma comprising the steps of: i) providing a serum or plasma sample to be tested; ii) determining a protein signature of the test sample by measuring the presence and/or amount in the test sample of one or more proteins selected from the group defined in table 2; wherein the survival time of an individual is identified in the event that the presence and/or amount in the test sample of one or more proteins selected from the group defined in table 2 is indicative of a survival time of less than 12 months or longer than 12 months or longer than 24 months.6. the method according to claim 5 further comprising the steps of: iii) providing a first control serum or plasma sample from an individual having a survival time of less than 12 months and/or a second control serum or plasma sample from an individual having a survival time longer than 12 months and/or longer than 24 months; iv) determining a protein signature of the first and/or the second control sample by measuring the presence and/or amount of the one or more proteins measured in step (ii); wherein the survival time of an individual is identified by comparing the presence and/or amount of the one or more proteins in the test sample measured in step (ii) with the presence and/or amount of the one or more proteins in the first and/or second control sample measured in step (iv).7. the method according to claim 5 wherein step (ii) comprises measuring the presence and/or amount in the test sample of all of the proteins defined in table 2.8. the method according to claim 1 wherein step (b) and/or step (d) is performed using a first binding agent capable of binding to the one or more proteins.9. the method according to claim 5 wherein step (ii) and/or step (iv) is performed using a first binding agent capable of binding to the one or more proteins.10. the method according to claim 8 wherein the first binding agent is an antibody or a fragment thereof.11. the method according to claim 9 wherein the first binding agent antibody or fragment thereof is a recombinant antibody or fragment thereof.12. the method according to claim 1 wherein the one or more proteins in the test sample is labelled with a detectable moiety.13. the method according to claim 5 wherein the one or more proteins in the test sample is labelled with a detectable moiety.14. the method according to claim 1 wherein step (b) and/or step (d) is performed using an array.15. the method according to claim 5 wherein step (ii) and/or step (iv) is performed using an array.16. the method according to claim 1 wherein step (b) and/or step (d) is performed using an assay comprising a second binding agent capable of binding to the one or more proteins, the second binding agent having a detectable moiety.17. the method according to claim 5 wherein step (ii) and/or step (iv) is performed using an assay comprising a second binding agent capable of binding to the one or more proteins, the second binding agent having a detectable moiety.18. the method according to claim 16 wherein the second binding agent is an antibody or a fragment thereof.19. the method according to claim 17 wherein the second binding agent is an antibody or a fragment thereof.20. an array for determining the presence of pancreatic adenocarcinoma in an individual comprising one or more binding agent as defined in claim 8.21. an array according to claim 20 wherein the one or more binding agent is capable of binding to all of the proteins defined in table 1.22. an array for determining the survival time of an individual afflicted with pancreatic adenocarcinoma comprising one or more binding agent as defined in claim 9.23. an array according to claim 22 wherein the one or more binding agent is capable of binding to all of the proteins defined in table 2.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EP3340117_A1.txt</td>\n",
       "      <td>2017-11-15</td>\n",
       "      <td>2018-06-27</td>\n",
       "      <td>2016-12-20</td>\n",
       "      <td>G06N3/04,G06N3/063</td>\n",
       "      <td>INTEL CORPORATION</td>\n",
       "      <td>LIN, TSUNG-HAN</td>\n",
       "      <td>60327233</td>\n",
       "      <td>unsupervised learning using neuromorphic computing</td>\n",
       "      <td>a spiking neural network (snn) is implemented on a neuromorphic computers and includes a plurality of neurons, a first set of the plurality of synapses defining feed-forward connections from a first subset of the neurons to a second subset of the neurons, a second subset of the plurality of synapses to define recurrent connections between the second subset of neurons, and a third subset of the plurality of synapses to define feedback connections from the second subset of neurons to the first subset of neurons. a set of input vectors are provided to iteratively modify weight values of the plurality of synapses. each iteration involves selectively enabling and disabling the third subset of synapses with a different one of the input vectors applied to the snn. the weight values are iteratively adjusted to derive a solution to an equation comprising an unknown matrix variable and an unknown vector variable.</td>\n",
       "      <td>1. a method comprising: defining a spiking neural network (snn) comprising a plurality of artificial neurons interconnected by a plurality of artificial synapses, wherein the snn is to comprise: a first subset of the plurality of synapses to define feedforward connections from a first subset of the plurality of neurons to a second subset of the plurality of neurons, a second subset of the plurality of synapses to define recurrent connections between the second subset of neurons, and a third subset of the plurality of synapses to define feedback connections from the second subset of neurons to the first subset of neurons; disabling the third subset of synapses; providing a first input vector as an input to the snn with the third subset of synapses disabled; determining a first steady state condition for the snn when the first input vector is provided as the input to the snn and the third subset of synapses is disabled; determining first spiking rates of at least a subset of the plurality of neurons associated with the first steady state condition; enabling the third subset of synapses; providing a modified version of the first input vector as an input to the snn with the third subset of synapses enabled; determining a second steady state condition for the snn when the modified version of the first input vector is provided as the input to the snn and the third subset of synapses is enabled; determining second spiking rates of the first subset of neurons and the second subset of neurons, wherein the second spiking rates are associated with the second steady state condition; and modifying weights of the plurality of synapses based on a difference between the first spiking rates and the second spiking rates.2. the method of claim 1, wherein first steady state spiking rates and second steady state spiking rates are to be determined for both the first and second subsets of neurons.3. the method of any one of claims 1-2, wherein the weight values are to be modified according to equations: and wherein g comprises a matrix of weight values for the second subset of synapses, d comprises a matrix of weight values for the first subset of synapses, a1 comprises first steady state spiking rates of the second subset of neurons, a2 comprises second steady state spiking rates of the second subset of neurons, b1 comprises first steady state spiking rates of the first subset of neurons, b2 comprises second steady state spiking rates of the first subset of neurons, η1 comprises a first learning rate, and η2 comprises a second learning rate.4. the method of any one of claims 1-3, wherein a modified version of the respective input vector is to be provided to the snn when the third subset of synapses are enabled and the second steady state spiking rates are determined with the modified version of the respective input vector provided to the snn.5. the method of claim 4, wherein the respective input vector comprises xi and the modified version of the respective input vector is to be according to (1 - γ) xi, wherein γ is a variance coefficient.6. the method of any one of claims 1-5, wherein the snn is to be defined for a neuromorphic computing device to implement the snn.7. the method of claim 6, wherein defining the snn comprises providing definition data to the neuromorphic computing device to cause the neuromorphic computing device to implement the snn.8. the method of claim 7, wherein the plurality of synapses are to be defined within the neuromorphic computing device in one or more routing tables of the neuromorphic computing device.9. the method of any one of claims 7-8, wherein the neuromorphic computing device comprises a plurality of neuromorphic processing cores interconnected by one or more routers of the neuromorphic computing device.10. the method of any one of claims 1-9, wherein the instructions, when executed, further cause the machine to determine final steady state spiking rates for at least the second subset of neurons corresponding to the particular set of weight values.11. the method of claim 10, wherein the final steady state spiking rates are to correspond to values of an unknown vector in the equation.12. the method of claim 11, wherein the number of neurons in the snn is based on dimensions of the unknown matrix and a dimension of the unknown vector.13. the method of any one of claims 1-12, wherein random weight values are to be applied to the plurality of synapses as initial weight values for the plurality of synapses.14. the method of any one of claims 1-13, wherein the second subset of neurons are to correspond to a plurality of clusters and the unknown matrix is to correspond to unknown features of the plurality of clusters.15. a system comprising: a neuromorphic computing device comprising: one or more routers; a plurality of neuromorphic cores interconnected by the one or more routers, wherein each neuromorphic core in the plurality is to implement one or more artificial neurons in a particular spiking neural network and comprises: a processor; a memory to store one or more routing tables; a respective dendrite process to be executed using the processor; and a respective soma process to be executed using the processor, wherein the one or more routing tables define a plurality of artificial synapses to interconnect the artificial neurons to define a particular spiking neural network (snn), and the particular snn is to comprise: a first layer of artificial neurons, a second layer of artificial neurons, a first subset of the plurality of synapses to define feedforward connections from neurons in the first layer neurons to neurons in the second layer, a second subset of the plurality of synapses to define recurrent connections between neurons in the second layer, and a third subset of the plurality of synapses to define feedback connections from neurons in the second layer to neurons in the first layer; andlogic to: provide a set of input vectors to the particular snn; selectively enable and disable the third subset of synapses; iteratively adjust weight values for at least the first subset of synapses based on the set of input vectors to derive a solution to an equation comprising an unknown matrix variable and an unknown vector variable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WO2019070570_A1.txt</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>2019-04-11</td>\n",
       "      <td>2017-10-06</td>\n",
       "      <td>A61B5/103</td>\n",
       "      <td>TELLUS YOU CARE</td>\n",
       "      <td>HSU KEVINCOKE, TANIA</td>\n",
       "      <td>65993331</td>\n",
       "      <td>non-contact activity sensing network for elderly care</td>\n",
       "      <td>determining a physical state of a person includes detecting positions of different portions of the person, transforming detected positions of the person into a point cloud having a density that varies according to movement of each of the portions, correlating movement and position data from the point cloud with known physical state positions and transitions between different states, and choosing a particular physical state by matching the data from the point cloud with the particular physical state. positions of different portions of the person may be detected using a tracking device. the tracking device may be a non-contact tracking device. the tracking device may include at least one wide band radar. the tracking devices may communicate wirelessly with at least one server in a cloud computing system. the states may include walking, standing, sitting, laying down, turning in bed, falling, and/or departed.</td>\n",
       "      <td>1. a method of determining a physical state of a person, comprising:detecting positions of different portions of the person;transforming detected positions of the person into a point cloud having a density that varies according to movement of each of the portions;correlating movement and position data from the point cloud with known physical state positions and transitions between different states; andchoosing a particular physical state by matching the data from the point cloud with the particular physical state. 2. a method, according to claim 1, wherein positions of different portions of the person are detected using a tracking device.3. a method, according to claim 2, wherein the tracking device is a non-contact tracking device.4. a method, according to claim 2, wherein the tracking device includes at least one wide band radar. 5. a method, according to claim 4, wherein the tracking devices communicate wirelessly with at least one server in a cloud computing system.6. a method, according to claim 1, wherein the states include at least one of: walking, standing, sitting, laying down, turning in bed, falling, and departed.7. a method, according to claim 6, wherein falling is detected in response to the person transitioning from the walking state to the laying down state.8. a method, according to claim 7, wherein during the transitioning, the person is detected as having a progressively lower center of gravity of the point cloud.9. a method, according to claim 7, wherein an audio generating device communicates with the person following a fall to confirm the fall and offer basic instructions to the person.10. a method, according to claim 9, wherein a caregiver is contacted if the person does not move or communicate following the audio generating device communicating with the person.11. a method, according to claim 10, wherein the audio generating device includes a microphone that receives audio communication from the person.12. a method, according to claim 1, wherein each of the states is associated with point densities, sizes, orientations, centers of gravity, and dispositions of bounding boxes of the point clouds.13. a method, according to claim 12, wherein parametric representations of the bounding boxes, the point densities and positions of the centers of gravity of samples of different states are provided as input to a neural network classifier.14. a method, according to claim 13, wherein the neural network is trained by providing the neural network on a server in a cloud computing system that receives data from tracking devices that detect positions of different portions of the person and communicate wirelessly with the cloud computing system.15. a method, according to claim 14, wherein the neural network is a long short-term memory recurrent neural network.16. a method, according to claim 13, wherein the neural network classifier correlates movement and position data from the point cloud with known physical state positions and transitions between different states to choose the particular physical state.17. a method, according to claim 1, further comprising:maintaining information corresponding to customary routine state transitions and locations of the person.18. a method, according to claim 17, wherein customary routine state transitions and locations are determined by detecting clusters of points in a multi-dimensional space of sequences of objects, time intervals, locations, and state transitions that represent complex user behaviors.19. a method, according to claim 17, wherein an alarm is provided to a caretaker in response to the person deviating from the customary routine state transitions and locations.20. a method, according to claim 19, wherein deviating from the customary routine state transitions and locations includes cycling around a room for a prolonged period of time or repetitively moving back and forth between two objects.21. a method, according to claim 18, wherein the clusters of points corresponding to customary routines are provided to a cloud computing system for comparison with clusters of points corresponding to customary routines for other people to further categorize behaviors and improve detection of dangerous situations.22. a method, according to claim 1, wherein the person is in a room and objects in the room are initially detected by monitoring absolute coordinates of a bounding box of the point cloud in various user states.23. a method, according to claim 22, wherein the objects include at least one of: a bed, a table, a chair, a bookshelf, a door, or a window.24. a method, according to claim 22, wherein objects in the room are detected by subtracting multiple positions of the bounding box from the area of the room.25. a method, according to claim 24, wherein a bed is detected by observing the person in a laying down state at a certain height off the floor.26. a method, according to claim 25, wherein boundaries of the bed are determined by tracking bounding boxes corresponding to a laying down state, a sitting state either before or after entering the laying down state, and a standing state prior to entering the sitting.27. a method, according to claim 24, wherein a bed or a couch is detected by observing adjacent states of standing, sitting and laying down at a position corresponding to the bed or the couch.28. a method, according to claim 24, wherein a window is detected by observing the person standing a relatively long time at a boundary of the room.29. a non-transitory computer-readable medium containing software that determines a physical state of a person, the software comprising:executable code that detects positions of different portions of the person;executable code that transforms detected positions of the person into a point cloud having a density that varies according to movement of each of the portions;executable code that correlates movement and position data from the point cloud with known physical state positions and transitions between different states; andexecutable code that chooses a particular physical state by matching the data from the point cloud with the particular physical state.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US2016259635_A1.txt</td>\n",
       "      <td>2015-03-04</td>\n",
       "      <td>2016-09-08</td>\n",
       "      <td>2015-03-04</td>\n",
       "      <td>G06F15/18,G06F17/27,G06F8/65,G06F8/71,G06F9/44,G06F9/445,G06N99/00</td>\n",
       "      <td>IBM (INTERNATIONAL BUSINESS MACHINES CORPORATION)</td>\n",
       "      <td>EL MAGHRAOUI, KAOUTARJANN, JOEFONPATTNAIK, PRATAP C.PICKOVER CLIFFORD A.</td>\n",
       "      <td>56849635</td>\n",
       "      <td>software patch management incorporating sentiment analysis</td>\n",
       "      <td>a method and system are provided. the method includes generating, by a machine-based sentiment prediction generator, respective machine-determined sentiment predictions for each of a plurality of software patches using sentiment analysis. the method further includes setting, by a sentiment-based confidence value generator, a confidence value for each of the plurality of software patches based on the machine-determined sentiment predictions. the method also includes at least one of selecting and prioritizing, by a software patch selector and prioritizer, at least one of the plurality of software patches based on the respective confidence value therefor.</td>\n",
       "      <td>1. 1-18. (canceled)19. a computer program product for software patch management, the computer program product comprising a computer readable storage medium having program instructions embodied therewith, the program instructions executable by a computer to cause the computer to perform a method comprising: generating, by a machine-based sentiment prediction generator, respective machine-determined sentiment predictions for each of a plurality of software patches using sentiment analysis; setting, by a sentiment-based confidence value generator, a confidence value for each of the plurality of software patches based on the machine-determined sentiment predictions; and at least one of selecting and prioritizing, by a software patch selector and prioritizer, at least one of the plurality of software patches based on the respective confidence value therefor.20. a system, comprising: a machine-based sentiment prediction generator for generating respective machine-determined sentiment predictions for each of a plurality of software patches using sentiment analysis; a sentiment-based confidence value generator for setting a confidence value for each of the plurality of software patches based on the machine-determined sentiment predictions; and a software patch selector and prioritizer for at least one of selecting and prioritizing at least one of the plurality of software patches based on the respective confidence value therefor.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename filing_date publication_date priority_date                                                         ipc_classes                                                 assignee                                                                 inventors  docdb_family_id                                                          title  \\\n",
       "0  US2009216698_A1.txt  2008-02-22       2009-08-27    2008-02-22                                                  G06F15/18,G06N5/02  XEROX CORPORATIONANDREOLI, JEAN-MARCBOUCHARD, GUILLAUME                                    ANDREOLI, JEAN-MARCBOUCHARD, GUILLAUME         40999265              temporal events analysis employing tree induction   \n",
       "1  US2020018760_A1.txt  2019-09-23       2020-01-16    2007-03-27                                                          G01N33/574                                                IMMUNOVIA            BORREBAECK, CARL, ARNE, KRISTERWINGREN, LARS, BERTIL, CHRISTER         39493874  protein signature/markers for the detection of adenocarcinoma   \n",
       "2     EP3340117_A1.txt  2017-11-15       2018-06-27    2016-12-20                                                  G06N3/04,G06N3/063                                        INTEL CORPORATION                                                            LIN, TSUNG-HAN         60327233             unsupervised learning using neuromorphic computing   \n",
       "3  WO2019070570_A1.txt  2018-10-01       2019-04-11    2017-10-06                                                           A61B5/103                                          TELLUS YOU CARE                                                      HSU KEVINCOKE, TANIA         65993331          non-contact activity sensing network for elderly care   \n",
       "4  US2016259635_A1.txt  2015-03-04       2016-09-08    2015-03-04  G06F15/18,G06F17/27,G06F8/65,G06F8/71,G06F9/44,G06F9/445,G06N99/00        IBM (INTERNATIONAL BUSINESS MACHINES CORPORATION)  EL MAGHRAOUI, KAOUTARJANN, JOEFONPATTNAIK, PRATAP C.PICKOVER CLIFFORD A.         56849635     software patch management incorporating sentiment analysis   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  abstract  \\\n",
       "0                                                                                                                                           an events analysis method comprises: optimizing respective to a set of training data a set of branching transition likelihood parameters associating parent events of type k with child events of type k' in branching processes; inferring a most probable branching process for a set of input data comprising events based on the optimized set of branching transition likelihood parameters; and identifying rare or unusual events of the set of input data based on the inferred most probable branching process. an events analysis apparatus includes a probabilistic branching process learning engine configured to optimize the set of branching transition likelihood parameters, and a probabilistic branching process inference engine configured to infer the most probable branching process.   \n",
       "1                                                                                                                                                                                                        the present invention provides a method for determining the presence of pancreatic adenocarcinoma in an individual and/or for determining the survival time of an individual afflicted with pancreatic adenocarcinoma comprising the steps of: (a) providing a serum or plasma sample to be tested; and (b) determining a protein signature of the test sample by measuring the presence and/or amount in the test sample of one or more selected proteins; wherein the presence and/or amount in the test sample of one or more proteins selected from the group defined in table 1 is indicative of the presence of pancreatic adenocarcinoma. the invention also provides an array and a kit suitable for use in the methods of the invention.   \n",
       "2     a spiking neural network (snn) is implemented on a neuromorphic computers and includes a plurality of neurons, a first set of the plurality of synapses defining feed-forward connections from a first subset of the neurons to a second subset of the neurons, a second subset of the plurality of synapses to define recurrent connections between the second subset of neurons, and a third subset of the plurality of synapses to define feedback connections from the second subset of neurons to the first subset of neurons. a set of input vectors are provided to iteratively modify weight values of the plurality of synapses. each iteration involves selectively enabling and disabling the third subset of synapses with a different one of the input vectors applied to the snn. the weight values are iteratively adjusted to derive a solution to an equation comprising an unknown matrix variable and an unknown vector variable.   \n",
       "3  determining a physical state of a person includes detecting positions of different portions of the person, transforming detected positions of the person into a point cloud having a density that varies according to movement of each of the portions, correlating movement and position data from the point cloud with known physical state positions and transitions between different states, and choosing a particular physical state by matching the data from the point cloud with the particular physical state. positions of different portions of the person may be detected using a tracking device. the tracking device may be a non-contact tracking device. the tracking device may include at least one wide band radar. the tracking devices may communicate wirelessly with at least one server in a cloud computing system. the states may include walking, standing, sitting, laying down, turning in bed, falling, and/or departed.   \n",
       "4                                                                                                                                                                                                                                                                     a method and system are provided. the method includes generating, by a machine-based sentiment prediction generator, respective machine-determined sentiment predictions for each of a plurality of software patches using sentiment analysis. the method further includes setting, by a sentiment-based confidence value generator, a confidence value for each of the plurality of software patches based on the machine-determined sentiment predictions. the method also includes at least one of selecting and prioritizing, by a software patch selector and prioritizer, at least one of the plurality of software patches based on the respective confidence value therefor.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         claims  \n",
       "0  1. an events analyzer comprising: a probabilistic branching process learning engine configured to optimize respective to a set of training data a set of branching transition likelihood parameters associating parent events of type k with child events of type k′ in branching processes; and a probabilistic branching process inference engine configured to infer a most probable branching process for a set of input data comprising events based on the optimized set of branching transition likelihood parameters.2. the events analyzer as set forth in claim 1, wherein the set of branching transition likelihood parameters include: (i) type transition likelihood parameters indicative of likelihood that one or more events of type k′ follow an event of type k, and (ii) one or more lifetime parameters for each event type k indicative of a statistical lifetime of events of type k.3. the events analyzer as set forth in claim 2, wherein the probabilistic branching process learning engine models branching as a geometrical process.4. the events analyzer as set forth in claim 3, wherein the probabilistic branching process learning engine applies a maximum likelihood algorithm to optimize respective to the set of training data at least one of (i) the type transition likelihood parameters and (ii) the lifetime parameters.5. the events analyzer as set forth in claim 1, wherein the probabilistic branching process learning engine applies a maximum likelihood algorithm to optimize the branching transition likelihood parameters respective to the set of training data.6. the events analyzer as set forth in claim 1, wherein the set of branching transition likelihood parameters include type transition likelihood parameters indicative of likelihood that one or more events of type k′ follow an event of type k, the type transition likelihood parameters being geometric distribution parameters.7. the events analyzer as set forth in claim 1, further comprising: a rare or unusual events identifier configured to identify rare or unusual events based on transition likelihoods of the most probable branching process.8. the events analyzer as set forth in claim 7, further comprising: a user interface including a display device configured to display a plot of the set of input data with rare or unusual events emphasized in the displayed plot.9. the events analyzer as set forth in claim 7, further comprising: an events logger configured to receive and log events associated with a monitored device, the set of input data comprising events comprising at least a portion of the events logged by the events logger.10. the events analyzer as set forth in claim 9, wherein the events logger is configured to receive and log events associated with one or more printing devices.11. a computer readable medium or media encoded with instructions executable on a computer or other digital processing device to perform an events analysis method including (i) inferring a most probable branching process for a set of input data comprising events based on an optimized set of branching transition likelihood parameters and (ii) identifying rare or unusual events based on the inferred most probable branching process.12. the computer readable medium or media as set forth in claim 11, wherein the set of optimized branching transition likelihood parameters include: (i) type transition likelihood parameters indicative of likelihood that one or more events of type k′ follow an event of type k, and (ii) one or more lifetime parameters for each event type k indicative of a statistical lifetime of events of type k.13. the computer readable medium or media as set forth in claim 11, wherein the identifying includes identifying rare or unusual events based on transition likelihoods of the most probable branching process.14. the computer readable medium or media as set forth in claim 11, wherein the encoded events analysis method further includes displaying a plot of the set of input data with rare or unusual events emphasized in the displayed plot.15. the computer readable medium or media as set forth in claim 11, wherein the encoded events analysis method further includes receiving and logging events, the set of input data comprising at least a portion of the logged events.16. the computer readable medium or media as set forth in claim 11, wherein the encoded events analysis method further includes receiving and logging events from one or more printing devices, the set of input data comprising at least a portion of the logged printing device events.17. an events analysis method comprising: optimizing respective to a set of training data a set of branching transition likelihood parameters associating parent events of type k with child events of type k′ in branching processes; inferring a most probable branching process for a set of input data comprising events based on the optimized set of branching transition likelihood parameters; and identifying rare or unusual events of the set of input data based on the inferred most probable branching process.18. the events analysis method as set forth in claim 17, wherein set of the input data is different from the set of training data.19. the events analysis method as set forth in claim 17, wherein the set of branching transition likelihood parameters include: (i) type transition likelihood parameters indicative of likelihood that one or more events of type k follow an event of type k, and (ii) one or more lifetime parameters for each event type k indicative of a statistical lifetime of events of type k.20. the events analysis method as set forth in claim 19, wherein the optimizing comprises: applying a maximum likelihood algorithm to optimize respective to the set of training data at least one of (i) the type transition likelihood parameters and (ii) the lifetime parameters.21. the events analysis method as set forth in claim 19, wherein the optimizing comprises: applying a maximum likelihood algorithm to optimize the branching transition likelihood parameters respective to the set of training data.22. the events analysis method as set forth in claim 17, wherein the identifying comprises: identifying rare or unusual events based on transition likelihoods of the most probable branching process.23. the events analysis method as set forth in claim 17, further comprising: displaying a plot of the set of input data with rare or unusual events emphasized in the displayed plot.24. the events analyzer as set forth in claim 17, further comprising: receiving the set of input data comprising events from one or more printing devices.  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1. a method for determining the presence of pancreatic adenocarcinoma in an individual comprising the steps of: a) providing a serum or plasma sample to be tested; b) determining a protein signature of the test sample by measuring the presence and/or amount in the test sample of one or more proteins selected from the group defined in table 1; wherein the presence and/or amount in the test sample of one or more proteins selected from the group defined in table 1 is indicative of the presence of pancreatic adenocarcinoma.2. the method according to claim 1 wherein the one or more proteins selected from the group defined in table 1 includes il-5 and c5.3. the method according to claim 1 further comprising the steps of: c) providing a control serum or plasma sample from an individual not afflicted with pancreatic adenocarcinoma; d) determining a protein signature of the control sample by measuring the presence and/or amount in the control sample of the one or more proteins measured in step (b); wherein the presence of pancreatic adenocarcinoma is identified in the event that the presence and/or amount in the test sample of the one or more proteins measured in step (b) is different from the presence and/or amount in the control sample of the one or more proteins measured in step (b).4. the method according to claim 1, wherein step (b) comprises measuring the presence and/or amount in the test sample of all of the proteins defined in table 1.5. a method for determining the survival time of an individual afflicted with pancreatic adenocarcinoma comprising the steps of: i) providing a serum or plasma sample to be tested; ii) determining a protein signature of the test sample by measuring the presence and/or amount in the test sample of one or more proteins selected from the group defined in table 2; wherein the survival time of an individual is identified in the event that the presence and/or amount in the test sample of one or more proteins selected from the group defined in table 2 is indicative of a survival time of less than 12 months or longer than 12 months or longer than 24 months.6. the method according to claim 5 further comprising the steps of: iii) providing a first control serum or plasma sample from an individual having a survival time of less than 12 months and/or a second control serum or plasma sample from an individual having a survival time longer than 12 months and/or longer than 24 months; iv) determining a protein signature of the first and/or the second control sample by measuring the presence and/or amount of the one or more proteins measured in step (ii); wherein the survival time of an individual is identified by comparing the presence and/or amount of the one or more proteins in the test sample measured in step (ii) with the presence and/or amount of the one or more proteins in the first and/or second control sample measured in step (iv).7. the method according to claim 5 wherein step (ii) comprises measuring the presence and/or amount in the test sample of all of the proteins defined in table 2.8. the method according to claim 1 wherein step (b) and/or step (d) is performed using a first binding agent capable of binding to the one or more proteins.9. the method according to claim 5 wherein step (ii) and/or step (iv) is performed using a first binding agent capable of binding to the one or more proteins.10. the method according to claim 8 wherein the first binding agent is an antibody or a fragment thereof.11. the method according to claim 9 wherein the first binding agent antibody or fragment thereof is a recombinant antibody or fragment thereof.12. the method according to claim 1 wherein the one or more proteins in the test sample is labelled with a detectable moiety.13. the method according to claim 5 wherein the one or more proteins in the test sample is labelled with a detectable moiety.14. the method according to claim 1 wherein step (b) and/or step (d) is performed using an array.15. the method according to claim 5 wherein step (ii) and/or step (iv) is performed using an array.16. the method according to claim 1 wherein step (b) and/or step (d) is performed using an assay comprising a second binding agent capable of binding to the one or more proteins, the second binding agent having a detectable moiety.17. the method according to claim 5 wherein step (ii) and/or step (iv) is performed using an assay comprising a second binding agent capable of binding to the one or more proteins, the second binding agent having a detectable moiety.18. the method according to claim 16 wherein the second binding agent is an antibody or a fragment thereof.19. the method according to claim 17 wherein the second binding agent is an antibody or a fragment thereof.20. an array for determining the presence of pancreatic adenocarcinoma in an individual comprising one or more binding agent as defined in claim 8.21. an array according to claim 20 wherein the one or more binding agent is capable of binding to all of the proteins defined in table 1.22. an array for determining the survival time of an individual afflicted with pancreatic adenocarcinoma comprising one or more binding agent as defined in claim 9.23. an array according to claim 22 wherein the one or more binding agent is capable of binding to all of the proteins defined in table 2.  \n",
       "2                                                                                                                                                                                                                                                                                                                                                             1. a method comprising: defining a spiking neural network (snn) comprising a plurality of artificial neurons interconnected by a plurality of artificial synapses, wherein the snn is to comprise: a first subset of the plurality of synapses to define feedforward connections from a first subset of the plurality of neurons to a second subset of the plurality of neurons, a second subset of the plurality of synapses to define recurrent connections between the second subset of neurons, and a third subset of the plurality of synapses to define feedback connections from the second subset of neurons to the first subset of neurons; disabling the third subset of synapses; providing a first input vector as an input to the snn with the third subset of synapses disabled; determining a first steady state condition for the snn when the first input vector is provided as the input to the snn and the third subset of synapses is disabled; determining first spiking rates of at least a subset of the plurality of neurons associated with the first steady state condition; enabling the third subset of synapses; providing a modified version of the first input vector as an input to the snn with the third subset of synapses enabled; determining a second steady state condition for the snn when the modified version of the first input vector is provided as the input to the snn and the third subset of synapses is enabled; determining second spiking rates of the first subset of neurons and the second subset of neurons, wherein the second spiking rates are associated with the second steady state condition; and modifying weights of the plurality of synapses based on a difference between the first spiking rates and the second spiking rates.2. the method of claim 1, wherein first steady state spiking rates and second steady state spiking rates are to be determined for both the first and second subsets of neurons.3. the method of any one of claims 1-2, wherein the weight values are to be modified according to equations: and wherein g comprises a matrix of weight values for the second subset of synapses, d comprises a matrix of weight values for the first subset of synapses, a1 comprises first steady state spiking rates of the second subset of neurons, a2 comprises second steady state spiking rates of the second subset of neurons, b1 comprises first steady state spiking rates of the first subset of neurons, b2 comprises second steady state spiking rates of the first subset of neurons, η1 comprises a first learning rate, and η2 comprises a second learning rate.4. the method of any one of claims 1-3, wherein a modified version of the respective input vector is to be provided to the snn when the third subset of synapses are enabled and the second steady state spiking rates are determined with the modified version of the respective input vector provided to the snn.5. the method of claim 4, wherein the respective input vector comprises xi and the modified version of the respective input vector is to be according to (1 - γ) xi, wherein γ is a variance coefficient.6. the method of any one of claims 1-5, wherein the snn is to be defined for a neuromorphic computing device to implement the snn.7. the method of claim 6, wherein defining the snn comprises providing definition data to the neuromorphic computing device to cause the neuromorphic computing device to implement the snn.8. the method of claim 7, wherein the plurality of synapses are to be defined within the neuromorphic computing device in one or more routing tables of the neuromorphic computing device.9. the method of any one of claims 7-8, wherein the neuromorphic computing device comprises a plurality of neuromorphic processing cores interconnected by one or more routers of the neuromorphic computing device.10. the method of any one of claims 1-9, wherein the instructions, when executed, further cause the machine to determine final steady state spiking rates for at least the second subset of neurons corresponding to the particular set of weight values.11. the method of claim 10, wherein the final steady state spiking rates are to correspond to values of an unknown vector in the equation.12. the method of claim 11, wherein the number of neurons in the snn is based on dimensions of the unknown matrix and a dimension of the unknown vector.13. the method of any one of claims 1-12, wherein random weight values are to be applied to the plurality of synapses as initial weight values for the plurality of synapses.14. the method of any one of claims 1-13, wherein the second subset of neurons are to correspond to a plurality of clusters and the unknown matrix is to correspond to unknown features of the plurality of clusters.15. a system comprising: a neuromorphic computing device comprising: one or more routers; a plurality of neuromorphic cores interconnected by the one or more routers, wherein each neuromorphic core in the plurality is to implement one or more artificial neurons in a particular spiking neural network and comprises: a processor; a memory to store one or more routing tables; a respective dendrite process to be executed using the processor; and a respective soma process to be executed using the processor, wherein the one or more routing tables define a plurality of artificial synapses to interconnect the artificial neurons to define a particular spiking neural network (snn), and the particular snn is to comprise: a first layer of artificial neurons, a second layer of artificial neurons, a first subset of the plurality of synapses to define feedforward connections from neurons in the first layer neurons to neurons in the second layer, a second subset of the plurality of synapses to define recurrent connections between neurons in the second layer, and a third subset of the plurality of synapses to define feedback connections from neurons in the second layer to neurons in the first layer; andlogic to: provide a set of input vectors to the particular snn; selectively enable and disable the third subset of synapses; iteratively adjust weight values for at least the first subset of synapses based on the set of input vectors to derive a solution to an equation comprising an unknown matrix variable and an unknown vector variable.  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                               1. a method of determining a physical state of a person, comprising:detecting positions of different portions of the person;transforming detected positions of the person into a point cloud having a density that varies according to movement of each of the portions;correlating movement and position data from the point cloud with known physical state positions and transitions between different states; andchoosing a particular physical state by matching the data from the point cloud with the particular physical state. 2. a method, according to claim 1, wherein positions of different portions of the person are detected using a tracking device.3. a method, according to claim 2, wherein the tracking device is a non-contact tracking device.4. a method, according to claim 2, wherein the tracking device includes at least one wide band radar. 5. a method, according to claim 4, wherein the tracking devices communicate wirelessly with at least one server in a cloud computing system.6. a method, according to claim 1, wherein the states include at least one of: walking, standing, sitting, laying down, turning in bed, falling, and departed.7. a method, according to claim 6, wherein falling is detected in response to the person transitioning from the walking state to the laying down state.8. a method, according to claim 7, wherein during the transitioning, the person is detected as having a progressively lower center of gravity of the point cloud.9. a method, according to claim 7, wherein an audio generating device communicates with the person following a fall to confirm the fall and offer basic instructions to the person.10. a method, according to claim 9, wherein a caregiver is contacted if the person does not move or communicate following the audio generating device communicating with the person.11. a method, according to claim 10, wherein the audio generating device includes a microphone that receives audio communication from the person.12. a method, according to claim 1, wherein each of the states is associated with point densities, sizes, orientations, centers of gravity, and dispositions of bounding boxes of the point clouds.13. a method, according to claim 12, wherein parametric representations of the bounding boxes, the point densities and positions of the centers of gravity of samples of different states are provided as input to a neural network classifier.14. a method, according to claim 13, wherein the neural network is trained by providing the neural network on a server in a cloud computing system that receives data from tracking devices that detect positions of different portions of the person and communicate wirelessly with the cloud computing system.15. a method, according to claim 14, wherein the neural network is a long short-term memory recurrent neural network.16. a method, according to claim 13, wherein the neural network classifier correlates movement and position data from the point cloud with known physical state positions and transitions between different states to choose the particular physical state.17. a method, according to claim 1, further comprising:maintaining information corresponding to customary routine state transitions and locations of the person.18. a method, according to claim 17, wherein customary routine state transitions and locations are determined by detecting clusters of points in a multi-dimensional space of sequences of objects, time intervals, locations, and state transitions that represent complex user behaviors.19. a method, according to claim 17, wherein an alarm is provided to a caretaker in response to the person deviating from the customary routine state transitions and locations.20. a method, according to claim 19, wherein deviating from the customary routine state transitions and locations includes cycling around a room for a prolonged period of time or repetitively moving back and forth between two objects.21. a method, according to claim 18, wherein the clusters of points corresponding to customary routines are provided to a cloud computing system for comparison with clusters of points corresponding to customary routines for other people to further categorize behaviors and improve detection of dangerous situations.22. a method, according to claim 1, wherein the person is in a room and objects in the room are initially detected by monitoring absolute coordinates of a bounding box of the point cloud in various user states.23. a method, according to claim 22, wherein the objects include at least one of: a bed, a table, a chair, a bookshelf, a door, or a window.24. a method, according to claim 22, wherein objects in the room are detected by subtracting multiple positions of the bounding box from the area of the room.25. a method, according to claim 24, wherein a bed is detected by observing the person in a laying down state at a certain height off the floor.26. a method, according to claim 25, wherein boundaries of the bed are determined by tracking bounding boxes corresponding to a laying down state, a sitting state either before or after entering the laying down state, and a standing state prior to entering the sitting.27. a method, according to claim 24, wherein a bed or a couch is detected by observing adjacent states of standing, sitting and laying down at a position corresponding to the bed or the couch.28. a method, according to claim 24, wherein a window is detected by observing the person standing a relatively long time at a boundary of the room.29. a non-transitory computer-readable medium containing software that determines a physical state of a person, the software comprising:executable code that detects positions of different portions of the person;executable code that transforms detected positions of the person into a point cloud having a density that varies according to movement of each of the portions;executable code that correlates movement and position data from the point cloud with known physical state positions and transitions between different states; andexecutable code that chooses a particular physical state by matching the data from the point cloud with the particular physical state.  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         1. 1-18. (canceled)19. a computer program product for software patch management, the computer program product comprising a computer readable storage medium having program instructions embodied therewith, the program instructions executable by a computer to cause the computer to perform a method comprising: generating, by a machine-based sentiment prediction generator, respective machine-determined sentiment predictions for each of a plurality of software patches using sentiment analysis; setting, by a sentiment-based confidence value generator, a confidence value for each of the plurality of software patches based on the machine-determined sentiment predictions; and at least one of selecting and prioritizing, by a software patch selector and prioritizer, at least one of the plurality of software patches based on the respective confidence value therefor.20. a system, comprising: a machine-based sentiment prediction generator for generating respective machine-determined sentiment predictions for each of a plurality of software patches using sentiment analysis; a sentiment-based confidence value generator for setting a confidence value for each of the plurality of software patches based on the machine-determined sentiment predictions; and a software patch selector and prioritizer for at least one of selecting and prioritizing at least one of the plurality of software patches based on the respective confidence value therefor.  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d993d110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216986"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8e2c7f",
   "metadata": {},
   "source": [
    "<h3>Keyword della professoressa:</h3>\n",
    "\n",
    "<img src=\"keyword prof.png\" style=\"width:800px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "19bbc9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_other = [\"molecule\",\n",
    "                  \"particle\", \n",
    "                  \"pharmacological\",\n",
    "                  \"technolog\",\n",
    "                  \"nano(-| )?tech(nolog)?\",\n",
    "                  \"alter(ing)?\",\n",
    "                  \"nano\",\n",
    "                  \"nano(-| )?bot\",\n",
    "                  \"nano(-| )?emulsion\",\n",
    "                  \"nano(-| )?particle\",\n",
    "                  \"nano(-| )?tube\",\n",
    "                  \"nano(-| )?sphere\",\n",
    "                  \"quantum\",\n",
    "                  \"graphene\",\n",
    "                  \"cloud\",\n",
    "                  \"software\",\n",
    "                  \"product\"\n",
    "                 ]\n",
    "\n",
    "keywords_cosmetics = [\"cosmetic\",\n",
    "                      \"beauty\", \n",
    "                      \"body\", \n",
    "                      \"skin\", \n",
    "                      \"nail\", \n",
    "                      \"fingernail\", \n",
    "                      \"cleans(e|ing)\", # \n",
    "                      \"manicur(e|ing)\", #manicure and manicuring\n",
    "                      \"varnish\", \n",
    "                      \"polish\",\n",
    "                      \"nail(s| |-)*polish\",\n",
    "                      \"lip(s)?\",\n",
    "                      \"lipstick\",\n",
    "                      \"blush\",\n",
    "                      \"mascara\",#<--\n",
    "                      \"make(s| |-)*up\",#makes up, make-up\n",
    "                      \"cream\",\n",
    "                      \"soap\",\n",
    "                      \"toothpaste\",\n",
    "                      \"sunscreen\",\n",
    "                      \"lotion\",\n",
    "                      \"deodorant\",\n",
    "                      \"lip(s| |-)*(polish)\",\n",
    "                      \"skin(s| |-)*(polish)\",\n",
    "                      \"skin(s| |-)*(polish)\",\n",
    "                      \"nail(s| |-)*(polish)\",\n",
    "                      \"baby(s| |-)*(polish)\",\n",
    "                      \"anti(-)?ag(e|ing)\"\n",
    "                     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "b2e8c718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8013ab62dd3a4a638c6288fb59fb4233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07634f81591482dac205c2d0cfded36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key in tqdm(keywords_cosmetics):\n",
    "    df[key] = df.title.str.count(key).fillna(0) + df.abstract.str.count(key).fillna(0) + df.claims.str.count(key).fillna(0)\n",
    "    \n",
    "for key in tqdm(keywords_other):\n",
    "    df[key] = df.title.str.count(key).fillna(0) + df.abstract.str.count(key).fillna(0) + df.claims.str.count(key).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "fcab23c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"total_cosmetics\"] = 0\n",
    "for key in keywords_cosmetics:\n",
    "    if key == \"body\" or key == \"lip(s)?\": continue\n",
    "    df[\"total_cosmetics\"] += df[key]\n",
    "    \n",
    "df[\"total_other\"] = 0\n",
    "for key in keywords_other:\n",
    "    df[\"total_other\"] += df[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "5e3c0a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lip(s)?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lip(s)?</th>\n",
       "      <th>total_cosmetics</th>\n",
       "      <th>filename</th>\n",
       "      <th>cosmetic</th>\n",
       "      <th>beauty</th>\n",
       "      <th>body</th>\n",
       "      <th>skin</th>\n",
       "      <th>nail</th>\n",
       "      <th>fingernail</th>\n",
       "      <th>cleans(e|ing)</th>\n",
       "      <th>manicur(e|ing)</th>\n",
       "      <th>varnish</th>\n",
       "      <th>polish</th>\n",
       "      <th>nail(s| |-)*polish</th>\n",
       "      <th>lip(s)?</th>\n",
       "      <th>lipstick</th>\n",
       "      <th>blush</th>\n",
       "      <th>mascara</th>\n",
       "      <th>make(s| |-)*up</th>\n",
       "      <th>cream</th>\n",
       "      <th>soap</th>\n",
       "      <th>toothpaste</th>\n",
       "      <th>sunscreen</th>\n",
       "      <th>lotion</th>\n",
       "      <th>deodorant</th>\n",
       "      <th>lip(s| |-)*(polish)</th>\n",
       "      <th>skin(s| |-)*(polish)</th>\n",
       "      <th>skin(s| |-)*(polish)</th>\n",
       "      <th>nail(s| |-)*(polish)</th>\n",
       "      <th>baby(s| |-)*(polish)</th>\n",
       "      <th>anti(-)?ag(e|ing)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70098</th>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>US2010272013_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10916</th>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WO2010123643_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147075</th>\n",
       "      <td>108.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WO2021001665_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119128</th>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>US8590058_B2.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142896</th>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>US2013031641_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120710</th>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WO2006132596_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166154</th>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>US8666677_B2.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195797</th>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WO2013170089_A2.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173670</th>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>US2015168428_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160241</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>US2002187997_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54888</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>US2019369147_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60786</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>US10313413_B2.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70427</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>US10789990_B2.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73899</th>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>US2019068671_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206703</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>US10884042_B2.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208063</th>\n",
       "      <td>47.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>US2018122511_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83123</th>\n",
       "      <td>47.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>US10366793_B2.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113772</th>\n",
       "      <td>47.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>WO2018112459_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27526</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WO2007103492_A2.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186074</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WO2007103492_A3.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lip(s)?  total_cosmetics             filename  cosmetic  beauty  body  skin  nail  fingernail  cleans(e|ing)  manicur(e|ing)  varnish  polish  nail(s| |-)*polish  lip(s)?  lipstick  blush  mascara  make(s| |-)*up  cream  soap  toothpaste  sunscreen  lotion  deodorant  lip(s| |-)*(polish)  skin(s| |-)*(polish)  skin(s| |-)*(polish)  nail(s| |-)*(polish)  baby(s| |-)*(polish)  anti(-)?ag(e|ing)\n",
       "70098     114.0              0.0  US2010272013_A1.txt       0.0     0.0   0.0   0.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0    114.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "10916     114.0              0.0  WO2010123643_A1.txt       0.0     0.0   0.0   0.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0    114.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "147075    108.0              0.0  WO2021001665_A1.txt       0.0     0.0   0.0   0.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0    108.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "119128    102.0              0.0     US8590058_B2.txt       0.0     0.0   0.0   0.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0    102.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "142896     83.0              0.0  US2013031641_A1.txt       0.0     0.0   0.0   0.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0     83.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "120710     79.0              0.0  WO2006132596_A1.txt       0.0     0.0   0.0   0.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0     79.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "166154     77.0              0.0     US8666677_B2.txt       0.0     0.0   0.0   0.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0     77.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "195797     71.0              0.0  WO2013170089_A2.txt       0.0     0.0   0.0   0.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0     71.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "173670     71.0              0.0  US2015168428_A1.txt       0.0     0.0   0.0   0.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0     71.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "160241     60.0              0.0  US2002187997_A1.txt       0.0     0.0   2.0   0.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0     60.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "54888      56.0              0.0  US2019369147_A1.txt       0.0     0.0   0.0   0.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0     56.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "60786      55.0              0.0    US10313413_B2.txt       0.0     0.0   0.0   0.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0     55.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "70427      54.0              0.0    US10789990_B2.txt       0.0     0.0   0.0   0.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0     54.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "73899      52.0              0.0  US2019068671_A1.txt       0.0     0.0   0.0   0.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0     52.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "206703     50.0              0.0    US10884042_B2.txt       0.0     0.0   0.0   0.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0     50.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "208063     47.0              2.0  US2018122511_A1.txt       0.0     0.0   1.0   2.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0     47.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "83123      47.0              2.0    US10366793_B2.txt       0.0     0.0   1.0   2.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0     47.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "113772     47.0              2.0  WO2018112459_A1.txt       0.0     0.0   1.0   2.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0     47.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "27526      45.0              0.0  WO2007103492_A2.txt       0.0     0.0   0.0   0.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0     45.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "186074     45.0              0.0  WO2007103492_A3.txt       0.0     0.0   0.0   0.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0     45.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = keywords_cosmetics[11] #12\n",
    "#5 - fingernail --> ricerca più approfondita (includere keyword product, 6 - cleans(e|ing)?)\n",
    "#11 - lip(s)?\n",
    "print(key)\n",
    "df[df[\"product\"] > 0].sort_values(by=key, ascending=False).head(20)[[key,\"total_cosmetics\", \"filename\"]+keywords_cosmetics].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "103c9bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lip(s)?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70098</th>\n",
       "      <td>establishing packet data network connectivity for local internet protocol access traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147075</th>\n",
       "      <td>methods for diagnosing multiple sclerosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119128</th>\n",
       "      <td>advanced audio captcha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120710</th>\n",
       "      <td>method and apparatus for audio clip classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166154</th>\n",
       "      <td>automated, objective and optimized feature selection in chemometric modeling (cluster resolution)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195797</th>\n",
       "      <td>compositions and methods for assessing cardiovascular disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160241</th>\n",
       "      <td>phospholipid transfer protein (pltp) and cholestoral metabolism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54888</th>\n",
       "      <td>power system inertia estimation using synchrophasor frequency measurements</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60786</th>\n",
       "      <td>detecting events from ingested communication signals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70427</th>\n",
       "      <td>video data learning and prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208063</th>\n",
       "      <td>method and system for characterizing microorganism-related conditions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27526</th>\n",
       "      <td>cellular predictive models for toxicities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178079</th>\n",
       "      <td>method and apparatus for adapting a context model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121097</th>\n",
       "      <td>methods and compositions for targeted imaging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167320</th>\n",
       "      <td>method and system for generating data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31856</th>\n",
       "      <td>confidence determination in a medical imaging video clip measurement based upon video clip image quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208936</th>\n",
       "      <td>virtual facial makeup removal, fast facial detection and landmark tracking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108249</th>\n",
       "      <td>method and apparatus for performing song detection in audio signal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>method and system for characterizing allergy-related conditions associated with microorganisms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91132</th>\n",
       "      <td>novel microorganisms producing a thermostable lipase and their use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176518</th>\n",
       "      <td>saliency mapping of imagery during artificially intelligent image classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7809</th>\n",
       "      <td>dynamicaly mixing and streaming media files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12982</th>\n",
       "      <td>cognitive bias determination and modeling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143659</th>\n",
       "      <td>long-term and continuous animal behavioral monitoring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205140</th>\n",
       "      <td>identification and use of biological parameters for diagnosis and treatment monitoring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15473</th>\n",
       "      <td>shape-based object detection and localization system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90914</th>\n",
       "      <td>vehicle monitor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157566</th>\n",
       "      <td>video-log production system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58955</th>\n",
       "      <td>mixing media files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186933</th>\n",
       "      <td>method and apparatus for safety monitoring of a body of water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173213</th>\n",
       "      <td>system and method for using a camera unit for the pool cleaning robot for safety monitoring and augmented reality games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39702</th>\n",
       "      <td>identity authentication method and apparatus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100126</th>\n",
       "      <td>phospholipid transfer protein (pltp) and cholesterol metabolism</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                          title\n",
       "70098                                  establishing packet data network connectivity for local internet protocol access traffic\n",
       "147075                                                                                methods for diagnosing multiple sclerosis\n",
       "119128                                                                                                   advanced audio captcha\n",
       "120710                                                                       method and apparatus for audio clip classification\n",
       "166154                        automated, objective and optimized feature selection in chemometric modeling (cluster resolution)\n",
       "195797                                                            compositions and methods for assessing cardiovascular disease\n",
       "160241                                                          phospholipid transfer protein (pltp) and cholestoral metabolism\n",
       "54888                                                power system inertia estimation using synchrophasor frequency measurements\n",
       "60786                                                                      detecting events from ingested communication signals\n",
       "70427                                                                                        video data learning and prediction\n",
       "208063                                                    method and system for characterizing microorganism-related conditions\n",
       "27526                                                                                 cellular predictive models for toxicities\n",
       "178079                                                                        method and apparatus for adapting a context model\n",
       "121097                                                                            methods and compositions for targeted imaging\n",
       "167320                                                                                    method and system for generating data\n",
       "31856                  confidence determination in a medical imaging video clip measurement based upon video clip image quality\n",
       "208936                                               virtual facial makeup removal, fast facial detection and landmark tracking\n",
       "108249                                                       method and apparatus for performing song detection in audio signal\n",
       "1486                             method and system for characterizing allergy-related conditions associated with microorganisms\n",
       "91132                                                        novel microorganisms producing a thermostable lipase and their use\n",
       "176518                                         saliency mapping of imagery during artificially intelligent image classification\n",
       "7809                                                                                dynamicaly mixing and streaming media files\n",
       "12982                                                                                 cognitive bias determination and modeling\n",
       "143659                                                                    long-term and continuous animal behavioral monitoring\n",
       "205140                                   identification and use of biological parameters for diagnosis and treatment monitoring\n",
       "15473                                                                      shape-based object detection and localization system\n",
       "90914                                                                                                           vehicle monitor\n",
       "157566                                                                                              video-log production system\n",
       "58955                                                                                                        mixing media files\n",
       "186933                                                            method and apparatus for safety monitoring of a body of water\n",
       "173213  system and method for using a camera unit for the pool cleaning robot for safety monitoring and augmented reality games\n",
       "39702                                                                              identity authentication method and apparatus\n",
       "100126                                                          phospholipid transfer protein (pltp) and cholesterol metabolism"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(key)\n",
    "df[df[\"product\"] > 0].sort_values(by=key, ascending=False).head(50)[[\"title\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c709988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "6798d42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>total_cosmetics</th>\n",
       "      <th>filename</th>\n",
       "      <th>cosmetic</th>\n",
       "      <th>beauty</th>\n",
       "      <th>body</th>\n",
       "      <th>skin</th>\n",
       "      <th>nail</th>\n",
       "      <th>fingernail</th>\n",
       "      <th>cleans(e|ing)</th>\n",
       "      <th>manicur(e|ing)</th>\n",
       "      <th>varnish</th>\n",
       "      <th>polish</th>\n",
       "      <th>nail(s| |-)*polish</th>\n",
       "      <th>lip(s)?</th>\n",
       "      <th>lipstick</th>\n",
       "      <th>blush</th>\n",
       "      <th>mascara</th>\n",
       "      <th>make(s| |-)*up</th>\n",
       "      <th>cream</th>\n",
       "      <th>soap</th>\n",
       "      <th>toothpaste</th>\n",
       "      <th>sunscreen</th>\n",
       "      <th>lotion</th>\n",
       "      <th>deodorant</th>\n",
       "      <th>lip(s| |-)*(polish)</th>\n",
       "      <th>skin(s| |-)*(polish)</th>\n",
       "      <th>skin(s| |-)*(polish)</th>\n",
       "      <th>nail(s| |-)*(polish)</th>\n",
       "      <th>baby(s| |-)*(polish)</th>\n",
       "      <th>anti(-)?ag(e|ing)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142126</th>\n",
       "      <td>242.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>US2017235848_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139942</th>\n",
       "      <td>238.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>US7437344_B2.txt</td>\n",
       "      <td>23.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20321</th>\n",
       "      <td>234.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>WO2011071542_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8521</th>\n",
       "      <td>219.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>US2003065636_A1.txt</td>\n",
       "      <td>23.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178389</th>\n",
       "      <td>185.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>US2018218436_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2808</th>\n",
       "      <td>151.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>US9747631_B2.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90708</th>\n",
       "      <td>147.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WO2019028269_A2.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170843</th>\n",
       "      <td>138.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>US2018053235_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48602</th>\n",
       "      <td>124.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>US2020315322_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15374</th>\n",
       "      <td>115.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>US2020387942_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65916</th>\n",
       "      <td>115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WO2020252498_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79480</th>\n",
       "      <td>112.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>WO0108023_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39592</th>\n",
       "      <td>105.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>US2003120534_A1.txt</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54048</th>\n",
       "      <td>103.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>US2003065578_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62536</th>\n",
       "      <td>100.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>US10552497_B2.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4767</th>\n",
       "      <td>100.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>US2018052932_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149253</th>\n",
       "      <td>100.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>US2020142938_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158857</th>\n",
       "      <td>99.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>US2011145093_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176294</th>\n",
       "      <td>98.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>US9805089_B2.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87435</th>\n",
       "      <td>92.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WO2020243528_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        product  total_cosmetics             filename  cosmetic  beauty  body  skin  nail  fingernail  cleans(e|ing)  manicur(e|ing)  varnish  polish  nail(s| |-)*polish  lip(s)?  lipstick  blush  mascara  make(s| |-)*up  cream  soap  toothpaste  sunscreen  lotion  deodorant  lip(s| |-)*(polish)  skin(s| |-)*(polish)  skin(s| |-)*(polish)  nail(s| |-)*(polish)  baby(s| |-)*(polish)  anti(-)?ag(e|ing)\n",
       "142126    242.0              1.0  US2017235848_A1.txt       0.0     0.0   5.0   1.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0      0.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "139942    238.0            111.0     US7437344_B2.txt      23.0    82.0   0.0   4.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0      2.0       0.0    1.0      1.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "20321     234.0              3.0  WO2011071542_A1.txt       0.0     0.0   0.0   0.0   3.0         0.0            0.0             0.0      0.0     0.0                 0.0      0.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "8521      219.0            102.0  US2003065636_A1.txt      23.0    73.0   0.0   4.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0      2.0       0.0    1.0      1.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "178389    185.0              2.0  US2018218436_A1.txt       0.0     0.0  17.0   2.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0      0.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "2808      151.0              3.0     US9747631_B2.txt       0.0     0.0   0.0   0.0   3.0         0.0            0.0             0.0      0.0     0.0                 0.0      0.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "90708     147.0              1.0  WO2019028269_A2.txt       0.0     0.0   0.0   1.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0      1.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "170843    138.0              5.0  US2018053235_A1.txt       0.0     0.0   0.0   5.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0      0.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "48602     124.0             14.0  US2020315322_A1.txt       0.0    14.0   0.0   0.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0      0.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "15374     115.0             68.0  US2020387942_A1.txt       0.0     0.0   0.0  68.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0      0.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "65916     115.0              1.0  WO2020252498_A1.txt       0.0     0.0   0.0   1.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0      0.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "79480     112.0              2.0     WO0108023_A1.txt       0.0     0.0   0.0   0.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0      0.0       0.0    0.0      0.0             2.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "39592     105.0             84.0  US2003120534_A1.txt      84.0     0.0   0.0   0.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0      0.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "54048     103.0             76.0  US2003065578_A1.txt       0.0    70.0   0.0   6.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0      0.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "62536     100.0              5.0    US10552497_B2.txt       0.0     0.0   0.0   5.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0      0.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "4767      100.0              5.0  US2018052932_A1.txt       0.0     0.0   0.0   5.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0      0.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "149253    100.0              5.0  US2020142938_A1.txt       0.0     0.0   0.0   5.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0      0.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "158857     99.0              3.0  US2011145093_A1.txt       0.0     0.0   0.0   0.0   3.0         0.0            0.0             0.0      0.0     0.0                 0.0      0.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "176294     98.0              2.0     US9805089_B2.txt       0.0     0.0   0.0   2.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0      0.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0\n",
       "87435      92.0              1.0  WO2020243528_A1.txt       0.0     0.0   0.0   1.0   0.0         0.0            0.0             0.0      0.0     0.0                 0.0      1.0       0.0    0.0      0.0             0.0    0.0   0.0         0.0        0.0     0.0        0.0                  0.0                   0.0                   0.0                   0.0                   0.0                0.0"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# per le cose di Jordanos\n",
    "\n",
    "key = keywords_other[16]\n",
    "print(key)\n",
    "df[df.total_cosmetics > 0].sort_values(by=key, ascending=False).head(20)[[key,\"total_cosmetics\", \"filename\"]+keywords_cosmetics].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "e8817ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142126</th>\n",
       "      <td>system and method for fuzzy concept mapping, voting ontology crowd sourcing, and technology prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139942</th>\n",
       "      <td>use of artificial intelligence in providing beauty advice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20321</th>\n",
       "      <td>systems and methods for purchasing products from a retail establishment using a mobile device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178389</th>\n",
       "      <td>virtual personal shopping system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90708</th>\n",
       "      <td>methods and systems for detection in an industrial internet of things data collection environment with large data sets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170843</th>\n",
       "      <td>unbiased search and user feedback analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48602</th>\n",
       "      <td>beauty product creation platform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15374</th>\n",
       "      <td>method of generating user feedback information to enhance product use results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79480</th>\n",
       "      <td>method for assembling and using a knowledge base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39592</th>\n",
       "      <td>cosmetic affinity indexing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54048</th>\n",
       "      <td>methods and systems involving simulated application of beauty products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62536</th>\n",
       "      <td>unbiasing search results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176294</th>\n",
       "      <td>local business and product search system and method</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87435</th>\n",
       "      <td>distribution and inventory system and methods of using the same</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                         title\n",
       "142126                  system and method for fuzzy concept mapping, voting ontology crowd sourcing, and technology prediction\n",
       "139942                                                               use of artificial intelligence in providing beauty advice\n",
       "20321                            systems and methods for purchasing products from a retail establishment using a mobile device\n",
       "178389                                                                                        virtual personal shopping system\n",
       "90708   methods and systems for detection in an industrial internet of things data collection environment with large data sets\n",
       "170843                                                                             unbiased search and user feedback analytics\n",
       "48602                                                                                         beauty product creation platform\n",
       "15374                                            method of generating user feedback information to enhance product use results\n",
       "79480                                                                         method for assembling and using a knowledge base\n",
       "39592                                                                                               cosmetic affinity indexing\n",
       "54048                                                   methods and systems involving simulated application of beauty products\n",
       "62536                                                                                                 unbiasing search results\n",
       "176294                                                                     local business and product search system and method\n",
       "87435                                                          distribution and inventory system and methods of using the same"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(key)\n",
    "df[(df.total_cosmetics > 0)].sort_values(by=key, ascending=False).head(20)[[\"title\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c910e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "637c9d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"methods and systems are disclosed for helping a consumer make a cosmetic product purchasing decision. a cosmetic service may maintain information reflective of compatibility between cosmetic products and personal characteristics of a plurality of subjects. the cosmetic service may also collect personal characteristic information from the consumer and compare the consumer's collected personal characteristic information with the maintained compatibility information. based on the comparison, the cosmetic service may determine a compatibility level of the consumer with each of a plurality of the cosmetic products. thereafter, the cosmetic service may present to the consumer an indication of a cosmetic product, and associate with the presented product, an indicator of predicted compatibility with the consumer.\""
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[39592][\"abstract\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "ea302a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'US2003120534_A1.txt'"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[39592][\"filename\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "218d6831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A23L5/40,A23P10/20,A61K8/02,A61K8/19,A61K8/73,B01J13/04,C08J3/12,C08J3/20,C08L1/08'"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[156472][\"ipc_classes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bffbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANALISI PIù APPROFONDITE\n",
    "\n",
    "#5 - fingernail --> ricerca più approfondita (includere keyword product, 6 - cleans(e|ing)?)\n",
    "#11 - lip(s)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "fc1ab918",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12217</th>\n",
       "      <td>shop-in-shop website construction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31520</th>\n",
       "      <td>composite particles, method of refining and use thereof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57629</th>\n",
       "      <td>apparatus and method for organization, segmentation, characterization, and discrimination of complex data sets from multi-heterogeneous sources</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65455</th>\n",
       "      <td>composite particles, method of refining and use thereof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67256</th>\n",
       "      <td>specimen preparation for transmission electron microscopy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69896</th>\n",
       "      <td>method for simulating the rendering of a make-up product on a body area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93818</th>\n",
       "      <td>apparatus and methods for detecting killer particles during chemical mechanical polishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95446</th>\n",
       "      <td>method for providing a customized product recommendation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99557</th>\n",
       "      <td>composite particles, method of refining and use thereof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108532</th>\n",
       "      <td>specimen preparation for transmission electron microscopy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119015</th>\n",
       "      <td>composite particles, method of refining and use thereof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125922</th>\n",
       "      <td>substrate retaining ring for cmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132382</th>\n",
       "      <td>shop-in-a-shop website construction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137111</th>\n",
       "      <td>specimen preparation for transmission electron microscopy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141628</th>\n",
       "      <td>machine learning systems for monitoring of semiconductor processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155008</th>\n",
       "      <td>composite particles, method of refining and use thereof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155869</th>\n",
       "      <td>method for providing a customized product recommendation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157748</th>\n",
       "      <td>method and apparatus for producing a barcode in a mouldable material</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158644</th>\n",
       "      <td>method for simulating the rendering of a make-up product on a body area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159920</th>\n",
       "      <td>specimen preparation for transmission electron microscopy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163843</th>\n",
       "      <td>identification and presentation of analogous beauty case histories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165679</th>\n",
       "      <td>composite particles, method of refining and use thereof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173098</th>\n",
       "      <td>composite particles, method of refining and use thereof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188965</th>\n",
       "      <td>shop-in-a-shop website construction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194374</th>\n",
       "      <td>advice information system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194452</th>\n",
       "      <td>apparatus and methods for detecting killer particles during chemical mechanical polishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206014</th>\n",
       "      <td>method for analyzing samples</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                  title\n",
       "12217                                                                                                                 shop-in-shop website construction\n",
       "31520                                                                                           composite particles, method of refining and use thereof\n",
       "57629   apparatus and method for organization, segmentation, characterization, and discrimination of complex data sets from multi-heterogeneous sources\n",
       "65455                                                                                           composite particles, method of refining and use thereof\n",
       "67256                                                                                         specimen preparation for transmission electron microscopy\n",
       "69896                                                                           method for simulating the rendering of a make-up product on a body area\n",
       "93818                                                         apparatus and methods for detecting killer particles during chemical mechanical polishing\n",
       "95446                                                                                          method for providing a customized product recommendation\n",
       "99557                                                                                           composite particles, method of refining and use thereof\n",
       "108532                                                                                        specimen preparation for transmission electron microscopy\n",
       "119015                                                                                          composite particles, method of refining and use thereof\n",
       "125922                                                                                                                 substrate retaining ring for cmp\n",
       "132382                                                                                                              shop-in-a-shop website construction\n",
       "137111                                                                                        specimen preparation for transmission electron microscopy\n",
       "141628                                                                              machine learning systems for monitoring of semiconductor processing\n",
       "155008                                                                                          composite particles, method of refining and use thereof\n",
       "155869                                                                                         method for providing a customized product recommendation\n",
       "157748                                                                             method and apparatus for producing a barcode in a mouldable material\n",
       "158644                                                                          method for simulating the rendering of a make-up product on a body area\n",
       "159920                                                                                        specimen preparation for transmission electron microscopy\n",
       "163843                                                                               identification and presentation of analogous beauty case histories\n",
       "165679                                                                                          composite particles, method of refining and use thereof\n",
       "173098                                                                                          composite particles, method of refining and use thereof\n",
       "188965                                                                                                              shop-in-a-shop website construction\n",
       "194374                                                                                                                        advice information system\n",
       "194452                                                        apparatus and methods for detecting killer particles during chemical mechanical polishing\n",
       "206014                                                                                                                     method for analyzing samples"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df[\"lip(s)?\"] > 0) & ((df.polish > 0)|(df[\"cleans(e|ing)\"] >0))][[\"title\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0b707f1b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12217</th>\n",
       "      <td>shop-in-shop website construction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31520</th>\n",
       "      <td>composite particles, method of refining and use thereof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57629</th>\n",
       "      <td>apparatus and method for organization, segmentation, characterization, and discrimination of complex data sets from multi-heterogeneous sources</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65455</th>\n",
       "      <td>composite particles, method of refining and use thereof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67256</th>\n",
       "      <td>specimen preparation for transmission electron microscopy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69896</th>\n",
       "      <td>method for simulating the rendering of a make-up product on a body area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93818</th>\n",
       "      <td>apparatus and methods for detecting killer particles during chemical mechanical polishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95446</th>\n",
       "      <td>method for providing a customized product recommendation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99557</th>\n",
       "      <td>composite particles, method of refining and use thereof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108532</th>\n",
       "      <td>specimen preparation for transmission electron microscopy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119015</th>\n",
       "      <td>composite particles, method of refining and use thereof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125922</th>\n",
       "      <td>substrate retaining ring for cmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132382</th>\n",
       "      <td>shop-in-a-shop website construction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137111</th>\n",
       "      <td>specimen preparation for transmission electron microscopy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141628</th>\n",
       "      <td>machine learning systems for monitoring of semiconductor processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155008</th>\n",
       "      <td>composite particles, method of refining and use thereof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155869</th>\n",
       "      <td>method for providing a customized product recommendation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157748</th>\n",
       "      <td>method and apparatus for producing a barcode in a mouldable material</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158644</th>\n",
       "      <td>method for simulating the rendering of a make-up product on a body area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159920</th>\n",
       "      <td>specimen preparation for transmission electron microscopy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163843</th>\n",
       "      <td>identification and presentation of analogous beauty case histories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165679</th>\n",
       "      <td>composite particles, method of refining and use thereof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173098</th>\n",
       "      <td>composite particles, method of refining and use thereof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188965</th>\n",
       "      <td>shop-in-a-shop website construction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194374</th>\n",
       "      <td>advice information system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194452</th>\n",
       "      <td>apparatus and methods for detecting killer particles during chemical mechanical polishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206014</th>\n",
       "      <td>method for analyzing samples</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                  title\n",
       "12217                                                                                                                 shop-in-shop website construction\n",
       "31520                                                                                           composite particles, method of refining and use thereof\n",
       "57629   apparatus and method for organization, segmentation, characterization, and discrimination of complex data sets from multi-heterogeneous sources\n",
       "65455                                                                                           composite particles, method of refining and use thereof\n",
       "67256                                                                                         specimen preparation for transmission electron microscopy\n",
       "69896                                                                           method for simulating the rendering of a make-up product on a body area\n",
       "93818                                                         apparatus and methods for detecting killer particles during chemical mechanical polishing\n",
       "95446                                                                                          method for providing a customized product recommendation\n",
       "99557                                                                                           composite particles, method of refining and use thereof\n",
       "108532                                                                                        specimen preparation for transmission electron microscopy\n",
       "119015                                                                                          composite particles, method of refining and use thereof\n",
       "125922                                                                                                                 substrate retaining ring for cmp\n",
       "132382                                                                                                              shop-in-a-shop website construction\n",
       "137111                                                                                        specimen preparation for transmission electron microscopy\n",
       "141628                                                                              machine learning systems for monitoring of semiconductor processing\n",
       "155008                                                                                          composite particles, method of refining and use thereof\n",
       "155869                                                                                         method for providing a customized product recommendation\n",
       "157748                                                                             method and apparatus for producing a barcode in a mouldable material\n",
       "158644                                                                          method for simulating the rendering of a make-up product on a body area\n",
       "159920                                                                                        specimen preparation for transmission electron microscopy\n",
       "163843                                                                               identification and presentation of analogous beauty case histories\n",
       "165679                                                                                          composite particles, method of refining and use thereof\n",
       "173098                                                                                          composite particles, method of refining and use thereof\n",
       "188965                                                                                                              shop-in-a-shop website construction\n",
       "194374                                                                                                                        advice information system\n",
       "194452                                                        apparatus and methods for detecting killer particles during chemical mechanical polishing\n",
       "206014                                                                                                                     method for analyzing samples"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df[\"lip(s)?\"] > 0) & ((df.polish > 0)|(df[\"cleans(e|ing)\"] >0))][[\"title\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5641553e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aa7361",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipc_class_dict[\"G06T11/60\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "c5e8d4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nAltri:\\n'US2017072530_A1.txt'\\n\""
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames_interesting_patents = set([\n",
    "    \"US2019191845_A1.txt\",\n",
    "    \"WO2020176430_A1.txt\",\n",
    "    \"US2020193399_A1.txt\",\n",
    "    \"US2019095747_A1.txt\",\n",
    "    \n",
    "    #lipstick\n",
    "    \"US2003065588_A1.txt\",\n",
    "    \n",
    "    #cri\n",
    "    \"US10321747_B2.txt\",\n",
    "    \"US2003120534_A1.txt\",\n",
    "    \"US2017024589_A1.txt\",\n",
    "    'WO2020219612_A1.txt',\n",
    "    'US2020405037_A1.txt', #<-p\n",
    "    'US7437344_B2.txt',\n",
    "    'US2003065578_A1.txt',\n",
    "    'WO2018232510_A1.txt',\n",
    "    'WO2020176430_A1.txt',\n",
    "    'US2020135310_A1.txt',\n",
    "    'US2020040373_A1.txt',\n",
    "    'WO2019014646_A1.txt',\n",
    "    'US2005227884_A1.txt',\n",
    "    'EP3628187_A1.txt',\n",
    "    \"US2003065636_A1.txt\",\n",
    "    'US2020297019_A1.txt',\n",
    "    \"US2003065255_A1.txt\",\n",
    "#Jordanos\n",
    "    \"US2020305587_A1.txt\",\n",
    "    \"US10449655_B2.txt\",\n",
    "    \"US2011098591_A1.txt\",\n",
    "    \"US10532019_B2.txt\",\n",
    "    'US2020305587_A1.txt',\n",
    "    \"WO2020227815_A1.txt\",\n",
    "    \"US2008040082_A1.txt\",\n",
    "    \"US2020375539_A1.txt\",\n",
    "    \"US2013191185_A1.txt\",\n",
    "    \"US2020315322_A1.txt\", #<--app\n",
    "    \n",
    "#DANIEL:\n",
    "    #1a make(s| |-)*up\n",
    "    'US2017358116_A1.txt',\n",
    "    'US10360710_B2.txt',\n",
    "    'WO2019014646_A1.txt',\n",
    "    #cream\n",
    "    'WO2020198546_A1.txt',\n",
    "    #soap\n",
    "    'US2020320846_A1.txt',\n",
    "    #toothpaste\n",
    "    'WO2015188178_A1.txt',\n",
    "    'US2020179089_A1.txt',\n",
    "    #sunscreen\n",
    "    'US2015313532_A1.txt',\n",
    "    'WO2013151614_A1.txt',\n",
    "    #lotion\n",
    "    'US2018188235_A1.txt',\n",
    "    'EP3409115_A2.txt',\n",
    "    'WO2020198546_A1.txt',\n",
    "    'EP3410318_A1.txt',\n",
    "    #deodorant\n",
    "    'US2013236417_A1.txt',\n",
    "    'WO2011130726_A2.txt',\n",
    "    #skin(s| |-)*care\n",
    "    'US2020387942_A1.txt',\n",
    "    'US10546658_B2.txt',\n",
    "    'US2019237194_A1.txt',\n",
    "    'WO2020060940_A1.txt',\n",
    "    'US2020375526_A1.txt',\n",
    "    #nail(s| |-)*care\n",
    "    'US2006282288_A1.txt',\n",
    "    #baby(s| |-)*care\n",
    "    'US2006271427_A1.txt',\n",
    "    'US2016092661_A1.txt',\n",
    "    'US2016306909_A1.txt',\n",
    "\n",
    "])\n",
    "\n",
    "\"\"\"\n",
    "Altri:\n",
    "'US2017072530_A1.txt'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "9b26a215",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6, G06T11/00: 2D [Two Dimensional] image generation +  (G06T11/00)\n",
      "\n",
      "5, G06Q30/06: Commerce, e.g. shopping or e-commerce + Buying, selling or leasing transactions (G06Q30/06)\n",
      "\n",
      "4, G06Q30/02: Commerce, e.g. shopping or e-commerce + Marketing, e.g. market research and analysis, sur (G06Q30/02)\n",
      "\n",
      "4, G16H50/20: ICT specially adapted for medical diagnosis, medical simulation or medical data mining; I (G16H50/20)\n",
      "\n",
      "3, G06K9/00: Methods or arrangements for recognising patterns (methods or arrangements for graph-readin (G06K9/00)\n",
      "\n",
      "3, G06F17/30: Digital computing or data processing equipment or methods, specially adapted for specific (G06F17/30)\n",
      "\n",
      "3, G16H10/60: ICT specially adapted for the handling or processing of patient-related medical or health (G16H10/60)\n",
      "\n",
      "3, G16H50/30: ICT specially adapted for medical diagnosis, medical simulation or medical data mining; I (G16H50/30)\n",
      "\n",
      "3, G06T11/60: 2D [Two Dimensional] image generation + Editing figures and text; Combining figures or te (G06T11/60)\n",
      "\n",
      "2, A01N31/02: Biocides, pest repellants or attractants, or plant growth regulators containing organic o (A01N31/02)\n",
      "\n",
      "2, A01N31/06: Biocides, pest repellants or attractants, or plant growth regulators containing organic o (A01N31/06)\n",
      "\n",
      "2, A01N33/04: Biocides, pest repellants or attractants, or plant growth regulators containing organic n (A01N33/04)\n",
      "\n",
      "2, A01N35/02: Biocides, pest repellants or attractants, or plant growth regulators containing organic c (A01N35/02)\n",
      "\n",
      "2, A01N35/06: Biocides, pest repellants or attractants, or plant growth regulators containing organic c (A01N35/06)\n",
      "\n",
      "2, A01N35/08: Biocides, pest repellants or attractants, or plant growth regulators containing organic c (A01N35/08)\n",
      "\n",
      "2, A01N37/02: Biocides, pest repellants or attractants, or plant growth regulators containing organic c (A01N37/02)\n",
      "\n",
      "2, A01N37/42: Biocides, pest repellants or attractants, or plant growth regulators containing organic c (A01N37/42)\n",
      "\n",
      "2, A01N41/10: Biocides, pest repellants or attractants, or plant growth regulators containing organic c (A01N41/10)\n",
      "\n",
      "2, A01N43/08: Biocides, pest repellants or attractants, or plant growth regulators containing heterocyc (A01N43/08)\n",
      "\n",
      "2, A01N43/10: Biocides, pest repellants or attractants, or plant growth regulators containing heterocyc (A01N43/10)\n",
      "\n",
      "2, A01N43/36: Biocides, pest repellants or attractants, or plant growth regulators containing heterocyc (A01N43/36)\n",
      "\n",
      "2, G01N33/50: Investigating or analysing materials by specific methods not covered by groups G01N000100 (G01N33/50)\n",
      "\n",
      "2, G06F15/00: Digital computers in general (details G06F0001000000-G06F0013000000); Data processing equ (G06F15/00)\n",
      "\n",
      "2, G06F15/18: Digital computers in general; Data processing equipment in general + in which a programme (G06F15/18)\n",
      "\n",
      "2, G06F7/00: Methods or arrangements for processing data by operating upon the order or content of the  (G06F7/00)\n",
      "\n",
      "2, G06N5/04: Computing arrangements using knowledge-based models + Inference methods or devices (G06N5/04)\n",
      "\n",
      "2, G16H20/10: ICT specially adapted for therapies or health-improving plans, e.g. for handling prescrip (G16H20/10)\n",
      "\n",
      "2, G16H40/63: ICT specially adapted for the management or administration of healthcare resources or fac (G16H40/63)\n",
      "\n",
      "2, G06T7/73: Image analysis + using feature-based methods (G06T7/73)\n",
      "\n",
      "2, A61K9/00: Medicinal preparations characterised by special physical form +  (A61K9/00)\n",
      "\n",
      "2, C11D11/00: Special methods for preparing compositions containing mixtures of detergents +  (C11D11/00)\n",
      "\n",
      "1, G08B21/24: Alarms responsive to a single specified undesired or abnormal condition and not otherwise (G08B21/24)\n",
      "\n",
      "1, A61B8/08: Diagnosis using ultrasonic, sonic or infrasonic waves + Detecting organic movements or cha (A61B8/08)\n",
      "\n",
      "1, A61N5/067: Radiation therapy (devices or apparatus applicable to both therapy and diagnosis A61B0006 (A61N5/067)\n",
      "\n",
      "1, A61K8/368: Cosmetics or similar toilet preparations + with carboxyl groups directly bound to carbon  (A61K8/368)\n",
      "\n",
      "1, G06F17/10: Digital computing or data processing equipment or methods, specially adapted for specific (G06F17/10)\n",
      "\n",
      "1, G06Q99/00: Subject matter not provided for in other groups of this subclass +  (G06Q99/00)\n",
      "\n",
      "1, A61C19/04: Dental auxiliary appliances (dental chairs or accessories therefor, working stands whethe (A61C19/04)\n",
      "\n",
      "1, G06N20/00: Machine learning +  (G06N20/00)\n",
      "\n",
      "1, A01M1/10: Stationary means for catching or killing insects + Traps (A01M1/10)\n",
      "\n",
      "1, A01N33/00: Biocides, pest repellants or attractants, or plant growth regulators containing organic n (A01N33/00)\n",
      "\n",
      "1, G06Q30/00: Commerce, e.g. shopping or e-commerce +  (G06Q30/00)\n",
      "\n",
      "1, G06K9/46: Methods or arrangements for recognising patterns (methods or arrangements for graph-readin (G06K9/46)\n",
      "\n",
      "1, G06T7/136: Image analysis + involving thresholding (G06T7/136)\n",
      "\n",
      "1, C40B30/04: Methods of screening libraries + by measuring the ability to specifically bind a target m (C40B30/04)\n",
      "\n",
      "1, G01N33/68: Investigating or analysing materials by specific methods not covered by groups G01N000100 (G01N33/68)\n",
      "\n",
      "1, A61B5/0408\n",
      "\n",
      "1, G06T17/00: 3D modelling for computer graphics +  (G06T17/00)\n",
      "\n",
      "1, G16H10/65: ICT specially adapted for the handling or processing of patient-related medical or health (G16H10/65)\n",
      "\n",
      "1, H04W4/80: Services specially adapted for wireless communication networks; Facilities therefor + Serv (H04W4/80)\n",
      "\n",
      "1, C12Q1/02: Measuring or testing processes involving enzymes, nucleic acids or microorganisms (measuri (C12Q1/02)\n",
      "\n",
      "1, C12Q1/18: Measuring or testing processes involving enzymes, nucleic acids or microorganisms (measuri (C12Q1/18)\n",
      "\n",
      "1, C12Q1/68: Measuring or testing processes involving enzymes, nucleic acids or microorganisms (measuri (C12Q1/68)\n",
      "\n",
      "1, A61B5/107: Measuring for diagnostic purposes (radiation diagnosis A61B0006000000;diagnosis by ultras (A61B5/107)\n",
      "\n",
      "1, A61B90/00: Instruments, implements or accessories specially adapted for surgery or diagnosis and not (A61B90/00)\n",
      "\n",
      "1, A61B90/98: Instruments, implements or accessories specially adapted for surgery or diagnosis and not (A61B90/98)\n",
      "\n",
      "1, A61P31/10: Antiinfectives, i.e. antibiotics, antiseptics, chemotherapeutics + Antimycotics (A61P31/10)\n",
      "\n",
      "1, G16H80/00: ICT specially adapted for facilitating communication between medical practitioners or pat (G16H80/00)\n",
      "\n",
      "1, B41J3/407: Typewriters or selective printing or marking mechanisms characterised by the purpose for  (B41J3/407)\n",
      "\n",
      "1, G06T7/13: Image analysis + Edge detection (G06T7/13)\n",
      "\n",
      "1, C11D17/04: Detergent materials or soaps characterised by their shape or physical properties (shaping (C11D17/04)\n",
      "\n",
      "1, C11D3/18: Other compounding ingredients of detergent compositions covered in group C11D0001000000 +  (C11D3/18)\n",
      "\n",
      "1, C11D3/43: Other compounding ingredients of detergent compositions covered in group C11D0001000000 +  (C11D3/43)\n",
      "\n",
      "1, C11D7/24: Compositions of detergents based essentially on non-surface-active compounds + Hydrocarbon (C11D7/24)\n",
      "\n",
      "1, C11D7/26: Compositions of detergents based essentially on non-surface-active compounds + containing  (C11D7/26)\n",
      "\n",
      "1, G06Q50/04: Systems or methods specially adapted for specific business sectors, e.g. utilities or tou (G06Q50/04)\n",
      "\n",
      "1, G06Q20/12: Payment architectures, schemes or protocols (apparatus for performing or posting payment  (G06Q20/12)\n",
      "\n",
      "1, B24B37/10: Lapping machines or devices; Accessories (B24B0003000000 takes precedence) + for single s (B24B37/10)\n",
      "\n",
      "1, B24B49/12: Measuring or gauging equipment for controlling the feed movement of the grinding tool or  (B24B49/12)\n",
      "\n",
      "1, B24B53/017: Devices or means for dressing or conditioning abrasive surfaces + Devices or means for d (B24B53/017)\n",
      "\n",
      "1, A23K20/163: Accessory food factors for animal feeding-stuffs + Sugars; Polysaccharides (A23K20/163)\n",
      "\n",
      "1, A23K50/30: Feeding-stuffs specially adapted for particular animals + for swine (A23K50/30)\n",
      "\n",
      "1, A23K50/60: Feeding-stuffs specially adapted for particular animals + for weanlings (A23K50/60)\n",
      "\n",
      "1, A23K50/75: Feeding-stuffs specially adapted for particular animals + for poultry (A23K50/75)\n",
      "\n",
      "1, A23L33/00: Modifying nutritive qualities of foods; Dietetic products; Preparation or treatment there (A23L33/00)\n",
      "\n",
      "1, A23L33/125: Modifying nutritive qualities of foods; Dietetic products; Preparation or treatment ther (A23L33/125)\n",
      "\n",
      "1, A61K31/702: Medicinal preparations containing organic active ingredients + Oligosaccharides, i.e. ha (A61K31/702)\n",
      "\n",
      "1, A61K8/60: Cosmetics or similar toilet preparations + Sugars; Derivatives thereof (A61K8/60)\n",
      "\n",
      "1, A61Q1/00: Make-up preparations; Body powders; Preparations for removing make-up +  (A61Q1/00)\n",
      "\n",
      "1, A61Q11/00: Preparations for care of the teeth, of the oral cavity or of dentures, e.g. dentifrices o (A61Q11/00)\n",
      "\n",
      "1, A61Q19/00: Preparations for care of the skin +  (A61Q19/00)\n",
      "\n",
      "1, G16H20/70: ICT specially adapted for therapies or health-improving plans, e.g. for handling prescrip (G16H20/70)\n",
      "\n",
      "1, G16H30/20: ICT specially adapted for the handling or processing of medical images (computerised tomo (G16H30/20)\n",
      "\n",
      "1, G06G7/48: Devices in which the computing operation is performed by varying electric or magnetic quan (G06G7/48)\n",
      "\n",
      "1, G06Q10/00: Administration; Management +  (G06Q10/00)\n",
      "\n",
      "1, G06Q50/00: Systems or methods specially adapted for specific business sectors, e.g. utilities or tou (G06Q50/00)\n",
      "\n",
      "1, G07G1/00: Cash registers (alarm indicators G07G0003000000) +  (G07G1/00)\n",
      "\n",
      "1, A61K38/48: Medicinal preparations containing peptides (peptides containing beta-lactam rings A61K003 (A61K38/48)\n",
      "\n",
      "1, A61K47/02: Medicinal preparations characterised by the non-active ingredients used, e.g. carriers or (A61K47/02)\n",
      "\n",
      "1, A61K47/42: Medicinal preparations characterised by the non-active ingredients used, e.g. carriers or (A61K47/42)\n",
      "\n",
      "1, A61K8/06: Cosmetics or similar toilet preparations + Emulsions (A61K8/06)\n",
      "\n",
      "1, A61K8/64: Cosmetics or similar toilet preparations + Proteins; Peptides; Derivatives or degradation  (A61K8/64)\n",
      "\n",
      "1, A61K8/66: Cosmetics or similar toilet preparations + Enzymes (A61K8/66)\n",
      "\n",
      "1, A61K9/107: Medicinal preparations characterised by special physical form + Emulsions (A61K9/107)\n",
      "\n",
      "1, A61Q19/08: Preparations for care of the skin + Anti-ageing preparations (A61Q19/08)\n",
      "\n",
      "1, A61Q13/00: Formulations or additives for perfume preparations (essential oils or perfumes per seC11B (A61Q13/00)\n",
      "\n",
      "1, C11D3/50: Other compounding ingredients of detergent compositions covered in group C11D0001000000 +  (C11D3/50)\n",
      "\n",
      "1, G06F17/50: Digital computing or data processing equipment or methods, specially adapted for specific (G06F17/50)\n",
      "\n",
      "1, A23L5/40: Preparation or treatment of foods or foodstuffs, in general; Food or foodstuffs obtained t (A23L5/40)\n",
      "\n",
      "1, A23P10/20: Shaping or working of foodstuffs characterised by the products + Agglomerating; Granulati (A23P10/20)\n",
      "\n",
      "1, A61K8/02: Cosmetics or similar toilet preparations + characterised by special physical form (A61K8/02)\n",
      "\n",
      "1, A61K8/19: Cosmetics or similar toilet preparations + containing inorganic ingredients (A61K8/19)\n",
      "\n",
      "1, A61K8/73: Cosmetics or similar toilet preparations + Polysaccharides (A61K8/73)\n",
      "\n",
      "1, B01J13/04: Colloid chemistry, e.g. the production of colloidal materials or their solutions, not oth (B01J13/04)\n",
      "\n",
      "1, C08J3/12: Processes of treating or compounding macromolecular substances + Powdering or granulating (C08J3/12)\n",
      "\n",
      "1, C08J3/20: Processes of treating or compounding macromolecular substances + Compounding polymers with (C08J3/20)\n",
      "\n",
      "1, C08L1/08: Compositions of cellulose, modified cellulose, or cellulose derivatives + Cellulose deriva (C08L1/08)\n",
      "\n",
      "1, B60K28/00: Safety devices for propulsion-unit control, specially adapted for, or arranged in, vehicl (B60K28/00)\n",
      "\n",
      "1, B60K28/02: Safety devices for propulsion-unit control, specially adapted for, or arranged in, vehicl (B60K28/02)\n",
      "\n",
      "1, B60W50/08: Details of control systems for road vehicle drive control not related to the control of a (B60W50/08)\n",
      "\n",
      "1, B60W50/10: Details of control systems for road vehicle drive control not related to the control of a (B60W50/10)\n",
      "\n",
      "1, A61B5/08: Measuring for diagnostic purposes (radiation diagnosis A61B0006000000;diagnosis by ultraso (A61B5/08)\n",
      "\n",
      "1, B82Y5/00: Nanobiotechnology or nanomedicine, e.g. protein engineering or drug delivery +  (B82Y5/00)\n",
      "\n",
      "1, G06F3/0481: Input arrangements for transferring data to be processed into a form capable of being ha (G06F3/0481)\n",
      "\n",
      "1, G06F3/0484: Input arrangements for transferring data to be processed into a form capable of being ha (G06F3/0484)\n",
      "\n",
      "1, G06K7/10: Methods or arrangements for sensing record carriers (G06K0009000000 takes precedence;metho (G06K7/10)\n",
      "\n",
      "1, H04R1/08: Details of transducers (diaphragms H04R0007000000;characterised by the nature of the trans (H04R1/08)\n",
      "\n",
      "1, G16H20/00: ICT specially adapted for therapies or health-improving plans, e.g. for handling prescrip (G16H20/00)\n",
      "\n",
      "1, A61B5/1171: Measuring for diagnostic purposes (radiation diagnosis A61B0006000000;diagnosis by ultra (A61B5/1171)\n",
      "\n",
      "1, G06T7/00: Image analysis +  (G06T7/00)\n",
      "\n",
      "1, A46B9/02: Arrangements of the bristles in the brush body + Position or arrangement of bristles in re (A46B9/02)\n",
      "\n",
      "1, A61Q5/00: Preparations for care of the hair +  (A61Q5/00)\n",
      "\n",
      "1, G06N3/08: Computing arrangements based on biological models + Learning methods (G06N3/08)\n",
      "\n",
      "1, G06T19/00: Manipulating 3D models or images for computer graphics +  (G06T19/00)\n",
      "\n",
      "1, G09B3/06: Manually- or mechanically-operated teaching appliances working with questions and answers  (G09B3/06)\n",
      "\n",
      "1, G06T15/80: 3D [Three Dimensional] image rendering + Shading (G06T15/80)\n",
      "\n",
      "1, G06T5/40: Image enhancement or restoration + by the use of histogram techniques (G06T5/40)\n",
      "\n",
      "1, G06T7/40: Image analysis + Analysis of texture (depth or shape recovery from texture G06T0007529000) (G06T7/40)\n",
      "\n",
      "1, G06T7/44: Image analysis + using image operators, e.g. filters, edge density metrics or local histog (G06T7/44)\n",
      "\n",
      "1, G06T7/50: Image analysis + Depth or shape recovery (G06T7/50)\n",
      "\n",
      "1, G06T7/507: Image analysis + from shading (G06T0007586000 takes precedence) (G06T7/507)\n",
      "\n",
      "1, G06Q10/06: Administration; Management + Resources, workflows, human or project management, e.g. orga (G06Q10/06)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ipc_count = {}\n",
    "\n",
    "for filename in filenames_interesting_patents:\n",
    "    for ipc_class in df[df.filename == filename][\"ipc_classes\"].values[0].split(\",\"):\n",
    "        \n",
    "        if ipc_class in ipc_count:\n",
    "            ipc_count[ipc_class] +=1\n",
    "        else:\n",
    "            ipc_count[ipc_class] = 1\n",
    "\n",
    "for k, v in sorted(ipc_count.items(), key=lambda x: -x[1]):\n",
    "    if k in ipc_class_dict:\n",
    "        if k in very_interesting_ipc_classes or k in interesting_ipc_classes: continue\n",
    "        \n",
    "        print(f\"{v}, {ipc_class_dict[k].split(' - ')[-1][:100]} ({k})\\n\")\n",
    "    else:\n",
    "        print(f\"{v}, {k}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeecc92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ipc_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "b30bf817",
   "metadata": {},
   "outputs": [],
   "source": [
    "very_interesting_ipc_classes=set([\n",
    "    \"A45D44/00\", #Other cosmetic or personal care articles, e.g. for hairdressers' rooms\n",
    "    \"A45D29/14\",\n",
    "    \"A45D29/00\",\n",
    "    \"A61K8/33\",\n",
    "    \"A61K8/34\",\n",
    "    \"A61K8/35\",\n",
    "    \"A61Q15/00\",\n",
    "    \"A61Q19/10\",\n",
    "    \"C11B9/00\",\n",
    "    \"A23L27/10\",\n",
    "    \"A45D34/04\",\n",
    "    \"A45D31/00\",\n",
    "    \"A61K8/36\",\n",
    "    \"A46B9/04\",\n",
    "    \"A46B15/00\",\n",
    "    \"A61C17/22\",\n",
    "    \"A45D29/11\",\n",
    "    \"A45D29/12\",\n",
    "    \"A61K8/37\",\n",
    "    \n",
    "    #aggiunte manuali:\n",
    "])\n",
    "\n",
    "interesting_ipc_classes=[\n",
    "    \"A61B5/00\",\n",
    "    \"A61B5/103\",\n",
    "    \"G16H30/40\",\n",
    "    \"G06F19/00\",\n",
    "    \n",
    "    #aggiunte manuali:\n",
    "    \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "561e7860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d9fe924940484291c434e362eb3fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key in tqdm(very_interesting_ipc_classes):\n",
    "    df[key] = df.ipc_classes.str.count(key).fillna(0)\n",
    "    \n",
    "    \n",
    "df[\"total_very_interesting_ipc_classes\"] = 0\n",
    "for key in very_interesting_ipc_classes:\n",
    "    df[\"total_very_interesting_ipc_classes\"] += df[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0bedf8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>nano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>US2013236417_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>US10835028_B2.txt</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674</th>\n",
       "      <td>US2019192067_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3240</th>\n",
       "      <td>US10849406_B2.txt</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5337</th>\n",
       "      <td>US2016369204_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210786</th>\n",
       "      <td>WO2020225756_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213268</th>\n",
       "      <td>US2003065526_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214209</th>\n",
       "      <td>EP3479729_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215818</th>\n",
       "      <td>US2003065278_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216476</th>\n",
       "      <td>US2019340671_A1.txt</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   filename  nano\n",
       "538     US2013236417_A1.txt   0.0\n",
       "1243      US10835028_B2.txt   0.0\n",
       "2674    US2019192067_A1.txt   0.0\n",
       "3240      US10849406_B2.txt   0.0\n",
       "5337    US2016369204_A1.txt   0.0\n",
       "...                     ...   ...\n",
       "210786  WO2020225756_A1.txt   0.0\n",
       "213268  US2003065526_A1.txt   0.0\n",
       "214209     EP3479729_A1.txt   0.0\n",
       "215818  US2003065278_A1.txt   0.0\n",
       "216476  US2019340671_A1.txt   0.0\n",
       "\n",
       "[187 rows x 2 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.total_very_interesting_ipc_classes > 0][[\"filename\", \"nano\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
